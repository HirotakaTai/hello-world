"""
Parallelization ãƒ‘ã‚¿ãƒ¼ãƒ³
========================

ã“ã®ãƒ‘ã‚¿ãƒ¼ãƒ³ã¯ã€ã‚¿ã‚¹ã‚¯ã‚’ä¸¦åˆ—ã§å®Ÿè¡Œã™ã‚‹ã“ã¨ã§åŠ¹ç‡æ€§ã‚’å‘ä¸Šã•ã›ã‚‹æ–¹æ³•ã§ã™ã€‚

2ã¤ã®ä¸»è¦ãªãƒãƒªã‚¨ãƒ¼ã‚·ãƒ§ãƒ³ï¼š
1. Sectioningï¼ˆã‚»ã‚¯ã‚·ãƒ§ãƒ‹ãƒ³ã‚°ï¼‰: ã‚¿ã‚¹ã‚¯ã‚’ç‹¬ç«‹ã—ãŸã‚µãƒ–ã‚¿ã‚¹ã‚¯ã«åˆ†å‰²ã—ã€ä¸¦åˆ—å®Ÿè¡Œ
2. Votingï¼ˆæŠ•ç¥¨ï¼‰: åŒã˜ã‚¿ã‚¹ã‚¯ã‚’è¤‡æ•°å›å®Ÿè¡Œã—ã€çµæœã‚’é›†ç´„

ä¾‹ï¼š
- ã‚»ã‚¯ã‚·ãƒ§ãƒ‹ãƒ³ã‚°: é•·ã„æ–‡æ›¸ã‚’è¤‡æ•°ã®éƒ¨åˆ†ã«åˆ†ã‘ã¦åŒæ™‚ã«è¦ç´„
- æŠ•ç¥¨: åŒã˜è³ªå•ã«å¯¾ã—ã¦è¤‡æ•°ã®å›ç­”ã‚’ç”Ÿæˆã—ã€æœ€è‰¯ã®å›ç­”ã‚’é¸æŠ

ã“ã®ãƒ‘ã‚¿ãƒ¼ãƒ³ã®åˆ©ç‚¹ï¼š
- å‡¦ç†æ™‚é–“ã®çŸ­ç¸®
- ã‚ˆã‚Šé«˜ã„ç²¾åº¦ã¨ä¿¡é ¼æ€§
- è¤‡æ•°ã®è¦–ç‚¹ã‹ã‚‰ã®åˆ†æãŒå¯èƒ½
"""

import time
from concurrent.futures import ThreadPoolExecutor
from datetime import datetime
from typing import Any
from typing import Dict

from dotenv import load_dotenv
from langchain.schema import HumanMessage
from langchain.schema import SystemMessage
from langchain_openai import ChatOpenAI

# ===== ç’°å¢ƒå¤‰æ•°ã®èª­ã¿è¾¼ã¿ =====
load_dotenv()


class ParallelizationSystem:
    """
    ä¸¦åˆ—åŒ–ãƒ‘ã‚¿ãƒ¼ãƒ³ã®å®Ÿè£…ã‚¯ãƒ©ã‚¹
    ã‚»ã‚¯ã‚·ãƒ§ãƒ‹ãƒ³ã‚°ã¨æŠ•ç¥¨ã®ä¸¡æ–¹ã®ãƒ‘ã‚¿ãƒ¼ãƒ³ã‚’å®Ÿè£…
    """

    def __init__(self, max_workers: int = 3):
        # ===== ChatOpenAI ãƒ¢ãƒ‡ãƒ«ã®åˆæœŸåŒ– =====
        self.llm = ChatOpenAI(model="gpt-3.5-turbo", temperature=0.7)

        # ===== ä¸¦åˆ—å‡¦ç†ç”¨ã®ã‚¹ãƒ¬ãƒƒãƒ‰ãƒ—ãƒ¼ãƒ« =====
        self.max_workers = max_workers
        self.executor = ThreadPoolExecutor(max_workers=max_workers)

        # ===== å®Ÿè¡Œãƒ­ã‚°ã‚’ä¿å­˜ã™ã‚‹ãƒªã‚¹ãƒˆ =====
        self.execution_log = []

    def _log_execution(
        self,
        pattern_type: str,
        task_description: str,
        execution_time: float,
        results: Any,
    ):
        """
        å®Ÿè¡Œã‚’ãƒ­ã‚°ã«è¨˜éŒ²

        Args:
            pattern_type (str): ãƒ‘ã‚¿ãƒ¼ãƒ³ã®ç¨®é¡ï¼ˆsectioning/votingï¼‰
            task_description (str): ã‚¿ã‚¹ã‚¯ã®èª¬æ˜
            execution_time (float): å®Ÿè¡Œæ™‚é–“ï¼ˆç§’ï¼‰
            results (Any): å®Ÿè¡Œçµæœ
        """
        self.execution_log.append(
            {
                "pattern": pattern_type,
                "task": task_description,
                "execution_time": execution_time,
                "results_count": len(results) if isinstance(results, list) else 1,
                "timestamp": datetime.now().strftime("%Y-%m-%d %H:%M:%S"),
            }
        )

    def _call_llm_sync(
        self, system_prompt: str, user_prompt: str, task_id: str = ""
    ) -> Dict[str, Any]:
        """
        LLMã‚’åŒæœŸçš„ã«å‘¼ã³å‡ºã™ï¼ˆä¸¦åˆ—å‡¦ç†ç”¨ï¼‰

        Args:
            system_prompt (str): ã‚·ã‚¹ãƒ†ãƒ ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ
            user_prompt (str): ãƒ¦ãƒ¼ã‚¶ãƒ¼ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ
            task_id (str): ã‚¿ã‚¹ã‚¯IDï¼ˆãƒ­ã‚°ç”¨ï¼‰

        Returns:
            Dict[str, Any]: å®Ÿè¡Œçµæœ
        """
        start_time = time.time()

        messages = [
            SystemMessage(content=system_prompt),
            HumanMessage(content=user_prompt),
        ]

        try:
            response = self.llm.invoke(messages)
            execution_time = time.time() - start_time

            return {
                "task_id": task_id,
                "success": True,
                "response": response.content,
                "execution_time": execution_time,
                "error": None,
            }
        except Exception as e:
            execution_time = time.time() - start_time
            return {
                "task_id": task_id,
                "success": False,
                "response": None,
                "execution_time": execution_time,
                "error": str(e),
            }

    def sectioning_document_analysis(
        self, document: str, analysis_type: str = "è¦ç´„"
    ) -> Dict[str, Any]:
        """
        ã‚»ã‚¯ã‚·ãƒ§ãƒ‹ãƒ³ã‚°ãƒ‘ã‚¿ãƒ¼ãƒ³: æ–‡æ›¸ã‚’è¤‡æ•°ã®éƒ¨åˆ†ã«åˆ†å‰²ã—ã¦ä¸¦åˆ—åˆ†æ

        Args:
            document (str): åˆ†æã™ã‚‹æ–‡æ›¸
            analysis_type (str): åˆ†æã®ç¨®é¡ï¼ˆè¦ç´„ã€åˆ†æã€ç¿»è¨³ãªã©ï¼‰

        Returns:
            Dict[str, Any]: åˆ†æçµæœ
        """

        start_time = time.time()
        print(f"ğŸ“„ ã‚»ã‚¯ã‚·ãƒ§ãƒ‹ãƒ³ã‚°åˆ†æé–‹å§‹: {analysis_type}")

        # ===== æ–‡æ›¸ã‚’è¤‡æ•°ã®ã‚»ã‚¯ã‚·ãƒ§ãƒ³ã«åˆ†å‰² =====
        # ç°¡å˜ãªåˆ†å‰²æ–¹æ³•ï¼šæ®µè½ã”ã¨ã«åˆ†å‰²
        paragraphs = [p.strip() for p in document.split("\n\n") if p.strip()]

        # ===== ã‚»ã‚¯ã‚·ãƒ§ãƒ³ãŒå°‘ãªã„å ´åˆã¯æ–‡å­—æ•°ã§åˆ†å‰² =====
        if len(paragraphs) < 3:
            # æ–‡å­—æ•°ã«ã‚ˆã‚‹åˆ†å‰²
            section_size = len(document) // 3
            sections = [
                document[i : i + section_size]
                for i in range(0, len(document), section_size)
            ]
        else:
            sections = paragraphs

        print(f"ğŸ“Š æ–‡æ›¸ã‚’{len(sections)}å€‹ã®ã‚»ã‚¯ã‚·ãƒ§ãƒ³ã«åˆ†å‰²")

        # ===== å„ã‚»ã‚¯ã‚·ãƒ§ãƒ³ç”¨ã®ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’æº–å‚™ =====
        tasks = []

        system_prompt = f"""
        ã‚ãªãŸã¯æ–‡æ›¸åˆ†æã®å°‚é–€å®¶ã§ã™ã€‚
        ä¸ãˆã‚‰ã‚ŒãŸæ–‡æ›¸ã®ã‚»ã‚¯ã‚·ãƒ§ãƒ³ã«å¯¾ã—ã¦ã€{analysis_type}ã‚’è¡Œã£ã¦ãã ã•ã„ã€‚
        """

        for i, section in enumerate(sections):
            user_prompt = f"""
            ä»¥ä¸‹ã¯æ–‡æ›¸ã®ã‚»ã‚¯ã‚·ãƒ§ãƒ³{i + 1}ã§ã™ã€‚ã“ã®ã‚»ã‚¯ã‚·ãƒ§ãƒ³ã«å¯¾ã—ã¦{analysis_type}ã‚’è¡Œã£ã¦ãã ã•ã„ï¼š
            
            ã€ã‚»ã‚¯ã‚·ãƒ§ãƒ³{i + 1}ã€‘
            {section}
            
            ã“ã®ã‚»ã‚¯ã‚·ãƒ§ãƒ³ã®{analysis_type}ã‚’æ˜ç¢ºã§ç°¡æ½”ã«æä¾›ã—ã¦ãã ã•ã„ã€‚
            """

            tasks.append((system_prompt, user_prompt, f"section_{i + 1}"))

        # ===== ä¸¦åˆ—å®Ÿè¡Œ =====
        print("âš¡ ä¸¦åˆ—å‡¦ç†å®Ÿè¡Œä¸­...")
        futures = [
            self.executor.submit(self._call_llm_sync, sys_prompt, user_prompt, task_id)
            for sys_prompt, user_prompt, task_id in tasks
        ]

        # ===== çµæœã‚’åé›† =====
        section_results = []
        for future in futures:
            result = future.result()
            section_results.append(result)

            if result["success"]:
                print(f"âœ… {result['task_id']} å®Œäº† ({result['execution_time']:.2f}ç§’)")
            else:
                print(f"âŒ {result['task_id']} ã‚¨ãƒ©ãƒ¼: {result['error']}")

        # ===== çµæœã‚’çµ±åˆ =====
        print("ğŸ”„ çµæœçµ±åˆä¸­...")

        successful_results = [r for r in section_results if r["success"]]

        if successful_results:
            # ===== çµ±åˆãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ =====
            integration_system_prompt = f"""
            ã‚ãªãŸã¯æ–‡æ›¸çµ±åˆã®å°‚é–€å®¶ã§ã™ã€‚
            è¤‡æ•°ã®ã‚»ã‚¯ã‚·ãƒ§ãƒ³ã®{analysis_type}çµæœã‚’çµ±åˆã—ã€æ–‡æ›¸å…¨ä½“ã®ä¸€è²«ã—ãŸ{analysis_type}ã‚’ä½œæˆã—ã¦ãã ã•ã„ã€‚
            """

            section_summaries = "\n\n".join(
                [
                    f"ã€ã‚»ã‚¯ã‚·ãƒ§ãƒ³{i + 1}ã®{analysis_type}ã€‘\n{result['response']}"
                    for i, result in enumerate(successful_results)
                ]
            )

            integration_user_prompt = f"""
            ä»¥ä¸‹ã¯æ–‡æ›¸ã®å„ã‚»ã‚¯ã‚·ãƒ§ãƒ³ã®{analysis_type}çµæœã§ã™ã€‚
            ã“ã‚Œã‚‰ã‚’çµ±åˆã—ã¦ã€æ–‡æ›¸å…¨ä½“ã®åŒ…æ‹¬çš„ãª{analysis_type}ã‚’ä½œæˆã—ã¦ãã ã•ã„ï¼š
            
            {section_summaries}
            
            çµ±åˆã•ã‚ŒãŸ{analysis_type}ã¯ã€è«–ç†çš„ã§ä¸€è²«æ€§ãŒã‚ã‚Šã€å…ƒã®æ–‡æ›¸ã®ä¸»è¦ãªãƒã‚¤ãƒ³ãƒˆã‚’ã™ã¹ã¦å«ã‚€ã‚ˆã†ã«ã—ã¦ãã ã•ã„ã€‚
            """

            integration_result = self._call_llm_sync(
                integration_system_prompt, integration_user_prompt, "integration"
            )

            final_result = (
                integration_result["response"]
                if integration_result["success"]
                else "çµ±åˆã«å¤±æ•—ã—ã¾ã—ãŸ"
            )
        else:
            final_result = "ã™ã¹ã¦ã®ã‚»ã‚¯ã‚·ãƒ§ãƒ³å‡¦ç†ã«å¤±æ•—ã—ã¾ã—ãŸ"

        execution_time = time.time() - start_time

        # ===== ãƒ­ã‚°ã«è¨˜éŒ² =====
        self._log_execution(
            "sectioning", f"æ–‡æ›¸{analysis_type}", execution_time, section_results
        )

        print(f"ğŸ‰ ã‚»ã‚¯ã‚·ãƒ§ãƒ‹ãƒ³ã‚°åˆ†æå®Œäº† (ç·å®Ÿè¡Œæ™‚é–“: {execution_time:.2f}ç§’)")

        return {
            "pattern": "sectioning",
            "analysis_type": analysis_type,
            "sections_count": len(sections),
            "successful_sections": len(successful_results),
            "section_results": section_results,
            "integrated_result": final_result,
            "total_execution_time": execution_time,
        }

    def voting_quality_assessment(
        self, content: str, assessment_criteria: str, num_votes: int = 3
    ) -> Dict[str, Any]:
        """
        æŠ•ç¥¨ãƒ‘ã‚¿ãƒ¼ãƒ³: åŒã˜ã‚¿ã‚¹ã‚¯ã‚’è¤‡æ•°å›å®Ÿè¡Œã—ã€çµæœã‚’è©•ä¾¡ã—ã¦æœ€è‰¯ã®çµæœã‚’é¸æŠ

        Args:
            content (str): è©•ä¾¡ã™ã‚‹ã‚³ãƒ³ãƒ†ãƒ³ãƒ„
            assessment_criteria (str): è©•ä¾¡åŸºæº–
            num_votes (int): æŠ•ç¥¨æ•°ï¼ˆä¸¦åˆ—å®Ÿè¡Œæ•°ï¼‰

        Returns:
            Dict[str, Any]: è©•ä¾¡çµæœ
        """

        start_time = time.time()
        print(f"ğŸ—³ï¸ æŠ•ç¥¨è©•ä¾¡é–‹å§‹: {assessment_criteria} ({num_votes}ç¥¨)")

        # ===== ç•°ãªã‚‹è¦–ç‚¹ã‹ã‚‰ã®è©•ä¾¡ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’æº–å‚™ =====
        voting_prompts = [
            {
                "perspective": "å³æ ¼ãªè©•ä¾¡è€…",
                "system_prompt": f"""
                ã‚ãªãŸã¯å³æ ¼ã§æ‰¹åˆ¤çš„ãªè©•ä¾¡è€…ã§ã™ã€‚
                ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã‚’{assessment_criteria}ã®è¦³ç‚¹ã‹ã‚‰å³ã—ãè©•ä¾¡ã—ã¦ãã ã•ã„ã€‚
                å•é¡Œç‚¹ã‚„æ”¹å–„ç‚¹ã‚’ç©æ¥µçš„ã«æŒ‡æ‘˜ã—ã¦ãã ã•ã„ã€‚
                """,
                "task_id": "strict_evaluator",
            },
            {
                "perspective": "å»ºè¨­çš„ãªè©•ä¾¡è€…",
                "system_prompt": f"""
                ã‚ãªãŸã¯å»ºè¨­çš„ã§ãƒãƒ©ãƒ³ã‚¹ã®å–ã‚ŒãŸè©•ä¾¡è€…ã§ã™ã€‚
                ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã‚’{assessment_criteria}ã®è¦³ç‚¹ã‹ã‚‰å…¬å¹³ã«è©•ä¾¡ã—ã€
                è‰¯ã„ç‚¹ã¨æ”¹å–„ç‚¹ã®ä¸¡æ–¹ã‚’æŒ‡æ‘˜ã—ã¦ãã ã•ã„ã€‚
                """,
                "task_id": "balanced_evaluator",
            },
            {
                "perspective": "å°‚é–€å®¶è©•ä¾¡è€…",
                "system_prompt": f"""
                ã‚ãªãŸã¯ãã®åˆ†é‡ã®å°‚é–€å®¶ã¨ã—ã¦è©•ä¾¡ã‚’è¡Œã„ã¾ã™ã€‚
                å°‚é–€çš„ãªçŸ¥è­˜ã¨çµŒé¨“ã«åŸºã¥ã„ã¦ã€{assessment_criteria}ã®è¦³ç‚¹ã‹ã‚‰
                æ·±ã„æ´å¯Ÿã‚’æä¾›ã—ã¦ãã ã•ã„ã€‚
                """,
                "task_id": "expert_evaluator",
            },
            {
                "perspective": "ãƒ¦ãƒ¼ã‚¶ãƒ¼è¦–ç‚¹è©•ä¾¡è€…",
                "system_prompt": f"""
                ã‚ãªãŸã¯ä¸€èˆ¬ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®è¦–ç‚¹ã‹ã‚‰è©•ä¾¡ã‚’è¡Œã„ã¾ã™ã€‚
                {assessment_criteria}ã«ã¤ã„ã¦ã€ä½¿ã„ã‚„ã™ã•ã‚„ç†è§£ã—ã‚„ã™ã•ã‚’
                é‡è¦–ã—ã¦è©•ä¾¡ã—ã¦ãã ã•ã„ã€‚
                """,
                "task_id": "user_evaluator",
            },
            {
                "perspective": "é©æ–°æ€§è©•ä¾¡è€…",
                "system_prompt": f"""
                ã‚ãªãŸã¯é©æ–°æ€§ã¨å‰µé€ æ€§ã‚’é‡è¦–ã™ã‚‹è©•ä¾¡è€…ã§ã™ã€‚
                {assessment_criteria}ã®è¦³ç‚¹ã‹ã‚‰ã€ç‹¬å‰µæ€§ã‚„æ–°ã—ã„ã‚¢ãƒ—ãƒ­ãƒ¼ãƒã«
                æ³¨ç›®ã—ã¦è©•ä¾¡ã—ã¦ãã ã•ã„ã€‚
                """,
                "task_id": "innovation_evaluator",
            },
        ]

        # ===== æŒ‡å®šã•ã‚ŒãŸæ•°ã®è©•ä¾¡è€…ã‚’é¸æŠ =====
        selected_evaluators = voting_prompts[:num_votes]

        # ===== å„è©•ä¾¡è€…ã®ã‚¿ã‚¹ã‚¯ã‚’æº–å‚™ =====
        tasks = []
        for evaluator in selected_evaluators:
            user_prompt = f"""
            ä»¥ä¸‹ã®ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã‚’{assessment_criteria}ã®è¦³ç‚¹ã‹ã‚‰è©•ä¾¡ã—ã¦ãã ã•ã„ï¼š
            
            ã€è©•ä¾¡å¯¾è±¡ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã€‘
            {content}
            
            è©•ä¾¡çµæœã¯ä»¥ä¸‹ã®å½¢å¼ã§æä¾›ã—ã¦ãã ã•ã„ï¼š
            1. ç·åˆè©•ä¾¡ï¼ˆ1-10ç‚¹ï¼‰
            2. è‰¯ã„ç‚¹
            3. æ”¹å–„ç‚¹
            4. å…·ä½“çš„ãªæ¨å¥¨äº‹é …
            
            ã‚ãªãŸã®è¦–ç‚¹ï¼ˆ{evaluator["perspective"]}ï¼‰ã‹ã‚‰ç‡ç›´ãªè©•ä¾¡ã‚’ãŠé¡˜ã„ã—ã¾ã™ã€‚
            """

            tasks.append(
                (evaluator["system_prompt"], user_prompt, evaluator["task_id"])
            )

        # ===== ä¸¦åˆ—å®Ÿè¡Œ =====
        print("âš¡ è¤‡æ•°è©•ä¾¡è€…ã«ã‚ˆã‚‹ä¸¦åˆ—è©•ä¾¡å®Ÿè¡Œä¸­...")
        futures = [
            self.executor.submit(self._call_llm_sync, sys_prompt, user_prompt, task_id)
            for sys_prompt, user_prompt, task_id in tasks
        ]

        # ===== çµæœã‚’åé›† =====
        evaluation_results = []
        for future in futures:
            result = future.result()
            evaluation_results.append(result)

            if result["success"]:
                print(
                    f"âœ… {result['task_id']} è©•ä¾¡å®Œäº† ({result['execution_time']:.2f}ç§’)"
                )
            else:
                print(f"âŒ {result['task_id']} ã‚¨ãƒ©ãƒ¼: {result['error']}")

        # ===== æŠ•ç¥¨çµæœã‚’é›†ç´„ =====
        print("ğŸ“Š æŠ•ç¥¨çµæœé›†ç´„ä¸­...")

        successful_evaluations = [r for r in evaluation_results if r["success"]]

        if successful_evaluations:
            # ===== é›†ç´„ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ =====
            aggregation_system_prompt = f"""
            ã‚ãªãŸã¯è©•ä¾¡çµæœã®é›†ç´„å°‚é–€å®¶ã§ã™ã€‚
            è¤‡æ•°ã®è©•ä¾¡è€…ã«ã‚ˆã‚‹{assessment_criteria}ã®è©•ä¾¡çµæœã‚’åˆ†æã—ã€
            ç·åˆçš„ãªè©•ä¾¡ã¨æœ€çµ‚çš„ãªæ¨å¥¨äº‹é …ã‚’æä¾›ã—ã¦ãã ã•ã„ã€‚
            """

            all_evaluations = "\n\n".join(
                [
                    f"ã€{result['task_id']}ã®è©•ä¾¡ã€‘\n{result['response']}"
                    for result in successful_evaluations
                ]
            )

            aggregation_user_prompt = f"""
            ä»¥ä¸‹ã¯è¤‡æ•°ã®è©•ä¾¡è€…ã«ã‚ˆã‚‹è©•ä¾¡çµæœã§ã™ã€‚
            ã“ã‚Œã‚‰ã‚’ç·åˆã—ã¦ã€æœ€çµ‚çš„ãªè©•ä¾¡ãƒ¬ãƒãƒ¼ãƒˆã‚’ä½œæˆã—ã¦ãã ã•ã„ï¼š
            
            {all_evaluations}
            
            æœ€çµ‚ãƒ¬ãƒãƒ¼ãƒˆã«ã¯ä»¥ä¸‹ã‚’å«ã‚ã¦ãã ã•ã„ï¼š
            1. ç·åˆè©•ä¾¡ã‚¹ã‚³ã‚¢ï¼ˆå„è©•ä¾¡è€…ã®ã‚¹ã‚³ã‚¢ã®å¹³å‡ãªã©ï¼‰
            2. å…±é€šã—ã¦æŒ‡æ‘˜ã•ã‚ŒãŸè‰¯ã„ç‚¹
            3. å…±é€šã—ã¦æŒ‡æ‘˜ã•ã‚ŒãŸæ”¹å–„ç‚¹
            4. è©•ä¾¡è€…é–“ã®æ„è¦‹ã®ç›¸é•ç‚¹
            5. æœ€çµ‚çš„ãªæ¨å¥¨äº‹é …
            """

            aggregation_result = self._call_llm_sync(
                aggregation_system_prompt, aggregation_user_prompt, "final_aggregation"
            )

            final_assessment = (
                aggregation_result["response"]
                if aggregation_result["success"]
                else "é›†ç´„ã«å¤±æ•—ã—ã¾ã—ãŸ"
            )
        else:
            final_assessment = "ã™ã¹ã¦ã®è©•ä¾¡ã«å¤±æ•—ã—ã¾ã—ãŸ"

        execution_time = time.time() - start_time

        # ===== ãƒ­ã‚°ã«è¨˜éŒ² =====
        self._log_execution(
            "voting", f"{assessment_criteria}è©•ä¾¡", execution_time, evaluation_results
        )

        print(f"ğŸ‰ æŠ•ç¥¨è©•ä¾¡å®Œäº† (ç·å®Ÿè¡Œæ™‚é–“: {execution_time:.2f}ç§’)")

        return {
            "pattern": "voting",
            "assessment_criteria": assessment_criteria,
            "num_evaluators": len(selected_evaluators),
            "successful_evaluations": len(successful_evaluations),
            "individual_evaluations": evaluation_results,
            "final_assessment": final_assessment,
            "total_execution_time": execution_time,
        }

    def parallel_code_review(self, code: str, num_reviewers: int = 3) -> Dict[str, Any]:
        """
        ä¸¦åˆ—ã‚³ãƒ¼ãƒ‰ãƒ¬ãƒ“ãƒ¥ãƒ¼: è¤‡æ•°ã®è¦–ç‚¹ã‹ã‚‰ã‚³ãƒ¼ãƒ‰ã‚’åŒæ™‚ã«ãƒ¬ãƒ“ãƒ¥ãƒ¼

        Args:
            code (str): ãƒ¬ãƒ“ãƒ¥ãƒ¼ã™ã‚‹ã‚³ãƒ¼ãƒ‰
            num_reviewers (int): ãƒ¬ãƒ“ãƒ¥ã‚¢ãƒ¼æ•°

        Returns:
            Dict[str, Any]: ãƒ¬ãƒ“ãƒ¥ãƒ¼çµæœ
        """

        start_time = time.time()
        print(f"ğŸ‘¥ ä¸¦åˆ—ã‚³ãƒ¼ãƒ‰ãƒ¬ãƒ“ãƒ¥ãƒ¼é–‹å§‹ ({num_reviewers}äººã®ãƒ¬ãƒ“ãƒ¥ã‚¢ãƒ¼)")

        # ===== ç•°ãªã‚‹å°‚é–€æ€§ã‚’æŒã¤ãƒ¬ãƒ“ãƒ¥ã‚¢ãƒ¼ã‚’å®šç¾© =====
        reviewers = [
            {
                "name": "ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£å°‚é–€å®¶",
                "system_prompt": """
                ã‚ãªãŸã¯ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£å°‚é–€å®¶ã§ã™ã€‚
                ã‚³ãƒ¼ãƒ‰ã‚’ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£ã®è¦³ç‚¹ã‹ã‚‰è©³ç´°ã«ãƒ¬ãƒ“ãƒ¥ãƒ¼ã—ã¦ãã ã•ã„ã€‚
                è„†å¼±æ€§ã€ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£ãƒ›ãƒ¼ãƒ«ã€å±é™ºãªå®Ÿè£…ãƒ‘ã‚¿ãƒ¼ãƒ³ã‚’ç‰¹å®šã—ã¦ãã ã•ã„ã€‚
                """,
                "task_id": "security_reviewer",
            },
            {
                "name": "ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹å°‚é–€å®¶",
                "system_prompt": """
                ã‚ãªãŸã¯ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹æœ€é©åŒ–ã®å°‚é–€å®¶ã§ã™ã€‚
                ã‚³ãƒ¼ãƒ‰ã®å®Ÿè¡ŒåŠ¹ç‡ã€ãƒ¡ãƒ¢ãƒªä½¿ç”¨é‡ã€ã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ ã®åŠ¹ç‡æ€§ã‚’
                é‡ç‚¹çš„ã«ãƒ¬ãƒ“ãƒ¥ãƒ¼ã—ã¦ãã ã•ã„ã€‚
                """,
                "task_id": "performance_reviewer",
            },
            {
                "name": "ã‚³ãƒ¼ãƒ‰å“è³ªå°‚é–€å®¶",
                "system_prompt": """
                ã‚ãªãŸã¯ã‚³ãƒ¼ãƒ‰å“è³ªã¨ãƒ¡ãƒ³ãƒ†ãƒŠãƒ“ãƒªãƒ†ã‚£ã®å°‚é–€å®¶ã§ã™ã€‚
                å¯èª­æ€§ã€æ‹¡å¼µæ€§ã€ä¿å®ˆæ€§ã€è¨­è¨ˆãƒ‘ã‚¿ãƒ¼ãƒ³ã®é©ç”¨ã«ã¤ã„ã¦
                è©³ç´°ã«ãƒ¬ãƒ“ãƒ¥ãƒ¼ã—ã¦ãã ã•ã„ã€‚
                """,
                "task_id": "quality_reviewer",
            },
            {
                "name": "ãƒã‚°æ¤œå‡ºå°‚é–€å®¶",
                "system_prompt": """
                ã‚ãªãŸã¯ãƒã‚°æ¤œå‡ºã®å°‚é–€å®¶ã§ã™ã€‚
                è«–ç†ã‚¨ãƒ©ãƒ¼ã€ã‚¨ãƒƒã‚¸ã‚±ãƒ¼ã‚¹ã®å‡¦ç†ä¸å‚™ã€ä¾‹å¤–å‡¦ç†ã®å•é¡Œãªã©
                æ½œåœ¨çš„ãªãƒã‚°ã‚’ç‰¹å®šã—ã¦ãã ã•ã„ã€‚
                """,
                "task_id": "bug_reviewer",
            },
            {
                "name": "ãƒ™ã‚¹ãƒˆãƒ—ãƒ©ã‚¯ãƒ†ã‚£ã‚¹å°‚é–€å®¶",
                "system_prompt": """
                ã‚ãªãŸã¯ãƒ—ãƒ­ã‚°ãƒ©ãƒŸãƒ³ã‚°ãƒ™ã‚¹ãƒˆãƒ—ãƒ©ã‚¯ãƒ†ã‚£ã‚¹ã®å°‚é–€å®¶ã§ã™ã€‚
                ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°è¦ç´„ã€å‘½åè¦å‰‡ã€æ§‹é€ åŒ–ã®é©åˆ‡ã•ã‚’
                è©•ä¾¡ã—ã¦ãã ã•ã„ã€‚
                """,
                "task_id": "practices_reviewer",
            },
        ]

        # ===== æŒ‡å®šã•ã‚ŒãŸæ•°ã®ãƒ¬ãƒ“ãƒ¥ã‚¢ãƒ¼ã‚’é¸æŠ =====
        selected_reviewers = reviewers[:num_reviewers]

        # ===== å„ãƒ¬ãƒ“ãƒ¥ã‚¢ãƒ¼ã®ã‚¿ã‚¹ã‚¯ã‚’æº–å‚™ =====
        tasks = []
        for reviewer in selected_reviewers:
            user_prompt = f"""
            ä»¥ä¸‹ã®ã‚³ãƒ¼ãƒ‰ã‚’{reviewer["name"]}ã®è¦–ç‚¹ã‹ã‚‰ãƒ¬ãƒ“ãƒ¥ãƒ¼ã—ã¦ãã ã•ã„ï¼š
            
            ã€ãƒ¬ãƒ“ãƒ¥ãƒ¼å¯¾è±¡ã‚³ãƒ¼ãƒ‰ã€‘
            ```
            {code}
            ```
            
            ãƒ¬ãƒ“ãƒ¥ãƒ¼çµæœã¯ä»¥ä¸‹ã®å½¢å¼ã§æä¾›ã—ã¦ãã ã•ã„ï¼š
            1. ç·åˆè©•ä¾¡ï¼ˆ1-10ç‚¹ï¼‰
            2. ç™ºè¦‹ã•ã‚ŒãŸå•é¡Œç‚¹ï¼ˆå„ªå…ˆåº¦ä»˜ãï¼‰
            3. è‰¯ã„ç‚¹ãƒ»æ¨å¥¨ã§ãã‚‹ç‚¹
            4. å…·ä½“çš„ãªæ”¹å–„ææ¡ˆ
            5. ä¿®æ­£ãŒå¿…è¦ãªç®‡æ‰€ã®æŒ‡æ‘˜
            
            å°‚é–€åˆ†é‡ã®è¦³ç‚¹ã‹ã‚‰è©³ç´°ã§å®Ÿç”¨çš„ãªãƒ¬ãƒ“ãƒ¥ãƒ¼ã‚’ãŠé¡˜ã„ã—ã¾ã™ã€‚
            """

            tasks.append((reviewer["system_prompt"], user_prompt, reviewer["task_id"]))

        # ===== ä¸¦åˆ—å®Ÿè¡Œ =====
        print("âš¡ è¤‡æ•°ãƒ¬ãƒ“ãƒ¥ã‚¢ãƒ¼ã«ã‚ˆã‚‹ä¸¦åˆ—ãƒ¬ãƒ“ãƒ¥ãƒ¼å®Ÿè¡Œä¸­...")
        futures = [
            self.executor.submit(self._call_llm_sync, sys_prompt, user_prompt, task_id)
            for sys_prompt, user_prompt, task_id in tasks
        ]

        # ===== çµæœã‚’åé›† =====
        review_results = []
        for future in futures:
            result = future.result()
            review_results.append(result)

            if result["success"]:
                print(
                    f"âœ… {result['task_id']} ãƒ¬ãƒ“ãƒ¥ãƒ¼å®Œäº† ({result['execution_time']:.2f}ç§’)"
                )
            else:
                print(f"âŒ {result['task_id']} ã‚¨ãƒ©ãƒ¼: {result['error']}")

        # ===== ãƒ¬ãƒ“ãƒ¥ãƒ¼çµæœã‚’çµ±åˆ =====
        print("ğŸ“‹ ãƒ¬ãƒ“ãƒ¥ãƒ¼çµæœçµ±åˆä¸­...")

        successful_reviews = [r for r in review_results if r["success"]]

        if successful_reviews:
            # ===== çµ±åˆãƒ¬ãƒ“ãƒ¥ãƒ¼ãƒ¬ãƒãƒ¼ãƒˆä½œæˆ =====
            integration_system_prompt = """
            ã‚ãªãŸã¯ã‚³ãƒ¼ãƒ‰ãƒ¬ãƒ“ãƒ¥ãƒ¼ã®çµ±åˆå°‚é–€å®¶ã§ã™ã€‚
            è¤‡æ•°ã®å°‚é–€å®¶ã«ã‚ˆã‚‹ãƒ¬ãƒ“ãƒ¥ãƒ¼çµæœã‚’çµ±åˆã—ã€
            ç·åˆçš„ãªã‚³ãƒ¼ãƒ‰ãƒ¬ãƒ“ãƒ¥ãƒ¼ãƒ¬ãƒãƒ¼ãƒˆã‚’ä½œæˆã—ã¦ãã ã•ã„ã€‚
            """

            all_reviews = "\n\n".join(
                [
                    f"ã€{result['task_id']}ã®ãƒ¬ãƒ“ãƒ¥ãƒ¼ã€‘\n{result['response']}"
                    for result in successful_reviews
                ]
            )

            integration_user_prompt = f"""
            ä»¥ä¸‹ã¯è¤‡æ•°ã®å°‚é–€å®¶ã«ã‚ˆã‚‹ã‚³ãƒ¼ãƒ‰ãƒ¬ãƒ“ãƒ¥ãƒ¼çµæœã§ã™ã€‚
            ã“ã‚Œã‚‰ã‚’çµ±åˆã—ã¦ã€åŒ…æ‹¬çš„ãªãƒ¬ãƒ“ãƒ¥ãƒ¼ãƒ¬ãƒãƒ¼ãƒˆã‚’ä½œæˆã—ã¦ãã ã•ã„ï¼š
            
            {all_reviews}
            
            çµ±åˆãƒ¬ãƒãƒ¼ãƒˆã«ã¯ä»¥ä¸‹ã‚’å«ã‚ã¦ãã ã•ã„ï¼š
            1. ç·åˆè©•ä¾¡ã¨æ¦‚è¦
            2. æœ€å„ªå…ˆã§ä¿®æ­£ã™ã¹ãå•é¡Œ
            3. ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£ã€ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ã€å“è³ªã®å„è¦³ç‚¹ã‹ã‚‰ã®ä¸»è¦ãªæŒ‡æ‘˜äº‹é …
            4. è‰¯ã„ç‚¹ãƒ»è©•ä¾¡ã§ãã‚‹å®Ÿè£…
            5. æ®µéšçš„ãªæ”¹å–„ãƒ­ãƒ¼ãƒ‰ãƒãƒƒãƒ—
            6. æ¬¡ã®ãƒ¬ãƒ“ãƒ¥ãƒ¼ã¾ã§ã®ã‚¢ã‚¯ã‚·ãƒ§ãƒ³ã‚¢ã‚¤ãƒ†ãƒ 
            """

            integration_result = self._call_llm_sync(
                integration_system_prompt, integration_user_prompt, "review_integration"
            )

            final_review = (
                integration_result["response"]
                if integration_result["success"]
                else "çµ±åˆã«å¤±æ•—ã—ã¾ã—ãŸ"
            )
        else:
            final_review = "ã™ã¹ã¦ã®ãƒ¬ãƒ“ãƒ¥ãƒ¼ã«å¤±æ•—ã—ã¾ã—ãŸ"

        execution_time = time.time() - start_time

        # ===== ãƒ­ã‚°ã«è¨˜éŒ² =====
        self._log_execution("voting", "ã‚³ãƒ¼ãƒ‰ãƒ¬ãƒ“ãƒ¥ãƒ¼", execution_time, review_results)

        print(f"ğŸ‰ ä¸¦åˆ—ã‚³ãƒ¼ãƒ‰ãƒ¬ãƒ“ãƒ¥ãƒ¼å®Œäº† (ç·å®Ÿè¡Œæ™‚é–“: {execution_time:.2f}ç§’)")

        return {
            "pattern": "parallel_code_review",
            "num_reviewers": len(selected_reviewers),
            "successful_reviews": len(successful_reviews),
            "individual_reviews": review_results,
            "integrated_review": final_review,
            "total_execution_time": execution_time,
        }

    def get_performance_statistics(self) -> Dict[str, Any]:
        """
        ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹çµ±è¨ˆã‚’å–å¾—

        Returns:
            Dict[str, Any]: å®Ÿè¡Œçµ±è¨ˆ
        """

        if not self.execution_log:
            return {"total_executions": 0}

        # ===== ãƒ‘ã‚¿ãƒ¼ãƒ³åˆ¥çµ±è¨ˆ =====
        pattern_stats = {}
        total_time = 0

        for log_entry in self.execution_log:
            pattern = log_entry["pattern"]
            exec_time = log_entry["execution_time"]

            if pattern not in pattern_stats:
                pattern_stats[pattern] = {"count": 0, "total_time": 0, "avg_time": 0}

            pattern_stats[pattern]["count"] += 1
            pattern_stats[pattern]["total_time"] += exec_time
            total_time += exec_time

        # ===== å¹³å‡æ™‚é–“ã‚’è¨ˆç®— =====
        for pattern_data in pattern_stats.values():
            pattern_data["avg_time"] = (
                pattern_data["total_time"] / pattern_data["count"]
            )

        return {
            "total_executions": len(self.execution_log),
            "total_time": total_time,
            "pattern_statistics": pattern_stats,
            "average_execution_time": total_time / len(self.execution_log),
        }

    def cleanup(self):
        """
        ãƒªã‚½ãƒ¼ã‚¹ã‚’ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—
        """
        self.executor.shutdown(wait=True)
        print("ğŸ§¹ ãƒªã‚½ãƒ¼ã‚¹ã‚’ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—ã—ã¾ã—ãŸ")


# ===== ä½¿ç”¨ä¾‹ =====
def main():
    """
    Parallelizationãƒ‘ã‚¿ãƒ¼ãƒ³ã®ãƒ‡ãƒ¢ãƒ³ã‚¹ãƒˆãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³
    """
    print("=== Parallelization ãƒ‘ã‚¿ãƒ¼ãƒ³ã®ãƒ‡ãƒ¢ ===\n")

    # ===== ä¸¦åˆ—åŒ–ã‚·ã‚¹ãƒ†ãƒ ã®ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹ã‚’ä½œæˆ =====
    parallel_system = ParallelizationSystem(max_workers=4)

    try:
        # ===== ãƒ‡ãƒ¢1: ã‚»ã‚¯ã‚·ãƒ§ãƒ‹ãƒ³ã‚° - æ–‡æ›¸è¦ç´„ =====
        print("ğŸ“„ ãƒ‡ãƒ¢1: ã‚»ã‚¯ã‚·ãƒ§ãƒ‹ãƒ³ã‚° - é•·æ–‡æ›¸ã®ä¸¦åˆ—è¦ç´„")
        print("-" * 60)

        sample_document = """
        äººå·¥çŸ¥èƒ½ï¼ˆAIï¼‰ã®ç™ºå±•ã¯ã€ç¾ä»£ç¤¾ä¼šã«é©å‘½çš„ãªå¤‰åŒ–ã‚’ã‚‚ãŸã‚‰ã—ã¦ã„ã¾ã™ã€‚
        æ©Ÿæ¢°å­¦ç¿’ã€æ·±å±¤å­¦ç¿’ã€è‡ªç„¶è¨€èªå‡¦ç†ãªã©ã®æŠ€è¡“ãŒæ€¥é€Ÿã«é€²æ­©ã—ã€
        ç§ãŸã¡ã®æ—¥å¸¸ç”Ÿæ´»ã‹ã‚‰ãƒ“ã‚¸ãƒã‚¹ã€ç ”ç©¶ã¾ã§ã€ã‚ã‚‰ã‚†ã‚‹åˆ†é‡ã«å½±éŸ¿ã‚’ä¸ãˆã¦ã„ã¾ã™ã€‚
        
        ç‰¹ã«æ³¨ç›®ã™ã¹ãã¯ã€ç”ŸæˆAIã®ç™»å ´ã§ã™ã€‚ChatGPTã‚„GPT-4ãªã©ã®å¤§è¦æ¨¡è¨€èªãƒ¢ãƒ‡ãƒ«ã¯ã€
        äººé–“ã®ã‚ˆã†ãªè‡ªç„¶ãªå¯¾è©±èƒ½åŠ›ã‚’ç¤ºã—ã€æ–‡ç« ä½œæˆã€ç¿»è¨³ã€ãƒ—ãƒ­ã‚°ãƒ©ãƒŸãƒ³ã‚°æ”¯æ´ãªã©ã€
        å¤šæ§˜ãªã‚¿ã‚¹ã‚¯ã‚’é«˜ç²¾åº¦ã§å®Ÿè¡Œã§ãã‚‹ã‚ˆã†ã«ãªã‚Šã¾ã—ãŸã€‚
        ã“ã‚Œã«ã‚ˆã‚Šã€çŸ¥è­˜åŠ´åƒè€…ã®åƒãæ–¹ãŒå¤§ããå¤‰åŒ–ã™ã‚‹ã“ã¨ãŒäºˆæƒ³ã•ã‚Œã¾ã™ã€‚
        
        ä¸€æ–¹ã§ã€AIã®æ€¥é€Ÿãªç™ºå±•ã¯æ–°ãŸãªèª²é¡Œã‚‚ç”Ÿã¿å‡ºã—ã¦ã„ã¾ã™ã€‚
        é›‡ç”¨ã¸ã®å½±éŸ¿ã€ãƒ—ãƒ©ã‚¤ãƒã‚·ãƒ¼ã®å•é¡Œã€AIã®å€«ç†çš„ãªä½¿ç”¨ã€
        å½æƒ…å ±ã®æ‹¡æ•£ãƒªã‚¹ã‚¯ãªã©ã€ç¤¾ä¼šå…¨ä½“ã§å–ã‚Šçµ„ã‚€ã¹ãå•é¡ŒãŒå±±ç©ã—ã¦ã„ã¾ã™ã€‚
        
        æ•™è‚²åˆ†é‡ã§ã¯ã€AIã‚’æ´»ç”¨ã—ãŸå€‹åˆ¥æŒ‡å°ã‚·ã‚¹ãƒ†ãƒ ã‚„ã€
        å­¦ç¿’è€…ã®ç†è§£åº¦ã«å¿œã˜ãŸã‚«ã‚¹ã‚¿ãƒã‚¤ã‚ºã•ã‚ŒãŸæ•™æã®æä¾›ãŒå¯èƒ½ã«ãªã‚Šã¾ã—ãŸã€‚
        ã—ã‹ã—ã€æ•™è‚²è€…ã®å½¹å‰²ã®å¤‰åŒ–ã‚„ã€å­¦ç¿’è€…ã®æ‰¹åˆ¤çš„æ€è€ƒåŠ›ã®è‚²æˆãªã©ã®
        æ–°ãŸãªèª²é¡Œã«ã‚‚å¯¾å¿œã™ã‚‹å¿…è¦ãŒã‚ã‚Šã¾ã™ã€‚
        
        åŒ»ç™‚åˆ†é‡ã«ãŠã„ã¦ã‚‚ã€AIã¯è¨ºæ–­æ”¯æ´ã€è–¬ç‰©ç™ºè¦‹ã€å€‹åˆ¥åŒ–åŒ»ç™‚ãªã©ã§
        å¤§ããªè²¢çŒ®ã‚’æœãŸã—ã¦ã„ã¾ã™ã€‚ç”»åƒè¨ºæ–­ã«ãŠã„ã¦ã¯ã€
        ç†Ÿç·´ã—ãŸåŒ»å¸«ã¨åŒç­‰ã¾ãŸã¯ãã‚Œä»¥ä¸Šã®ç²¾åº¦ã‚’ç¤ºã™AIã‚·ã‚¹ãƒ†ãƒ ã‚‚ç™»å ´ã—ã¦ã„ã¾ã™ã€‚
        
        ä»Šå¾Œã€AIã¨äººé–“ãŒå”åƒã™ã‚‹ç¤¾ä¼šã‚’å®Ÿç¾ã™ã‚‹ãŸã‚ã«ã¯ã€
        æŠ€è¡“çš„ãªç™ºå±•ã ã‘ã§ãªãã€æ³•çš„æ çµ„ã¿ã®æ•´å‚™ã€
        å€«ç†çš„ã‚¬ã‚¤ãƒ‰ãƒ©ã‚¤ãƒ³ã®ç­–å®šã€ãã—ã¦äººã€…ã®AIãƒªãƒ†ãƒ©ã‚·ãƒ¼ã®å‘ä¸ŠãŒä¸å¯æ¬ ã§ã™ã€‚
        """

        sectioning_result = parallel_system.sectioning_document_analysis(
            document=sample_document, analysis_type="è¦ç´„"
        )

        print("\nğŸ“Š ã‚»ã‚¯ã‚·ãƒ§ãƒ‹ãƒ³ã‚°çµæœ:")
        print(f"- å‡¦ç†ã‚»ã‚¯ã‚·ãƒ§ãƒ³æ•°: {sectioning_result['sections_count']}")
        print(f"- æˆåŠŸã‚»ã‚¯ã‚·ãƒ§ãƒ³æ•°: {sectioning_result['successful_sections']}")
        print(f"- å®Ÿè¡Œæ™‚é–“: {sectioning_result['total_execution_time']:.2f}ç§’")
        print(f"\nçµ±åˆè¦ç´„:\n{sectioning_result['integrated_result'][:200]}...\n")

        # ===== ãƒ‡ãƒ¢2: æŠ•ç¥¨ - å“è³ªè©•ä¾¡ =====
        print("ğŸ—³ï¸ ãƒ‡ãƒ¢2: æŠ•ç¥¨ - è¤‡æ•°è©•ä¾¡è€…ã«ã‚ˆã‚‹å“è³ªè©•ä¾¡")
        print("-" * 60)

        sample_content = """
        ã€ãƒ—ãƒ­ãƒ€ã‚¯ãƒˆææ¡ˆæ›¸ã€‘
        
        é©æ–°çš„ãªAIæ­è¼‰å­¦ç¿’ã‚¢ãƒ—ãƒªã€ŒStudyMateã€
        
        æ¦‚è¦ï¼š
        StudyMateã¯ã€å€‹ã€…ã®å­¦ç¿’è€…ã«æœ€é©åŒ–ã•ã‚ŒãŸAIå­¦ç¿’æ”¯æ´ã‚¢ãƒ—ãƒªã§ã™ã€‚
        æ©Ÿæ¢°å­¦ç¿’ã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ ã‚’ä½¿ç”¨ã—ã¦å­¦ç¿’è€…ã®å¼±ç‚¹ã‚’ç‰¹å®šã—ã€
        ãƒ‘ãƒ¼ã‚½ãƒŠãƒ©ã‚¤ã‚ºã•ã‚ŒãŸå­¦ç¿’ãƒ—ãƒ©ãƒ³ã‚’æä¾›ã—ã¾ã™ã€‚
        
        ä¸»ãªæ©Ÿèƒ½ï¼š
        1. é©å¿œçš„å­¦ç¿’ã‚·ã‚¹ãƒ†ãƒ  - å­¦ç¿’è€…ã®ç†è§£åº¦ã«å¿œã˜ã¦é›£æ˜“åº¦ã‚’èª¿æ•´
        2. ã‚¤ãƒ³ã‚¿ãƒ©ã‚¯ãƒ†ã‚£ãƒ–ãªQ&A - AI ãƒãƒ¥ãƒ¼ã‚¿ãƒ¼ã¨ã®å¯¾è©±å‹å­¦ç¿’
        3. é€²æ—è¿½è·¡ã¨ã‚¢ãƒŠãƒªãƒ†ã‚£ã‚¯ã‚¹ - è©³ç´°ãªå­¦ç¿’ãƒ‡ãƒ¼ã‚¿ã®å¯è¦–åŒ–
        4. ã‚²ãƒ¼ãƒŸãƒ•ã‚£ã‚±ãƒ¼ã‚·ãƒ§ãƒ³è¦ç´  - ãƒã‚¤ãƒ³ãƒˆåˆ¶åº¦ã¨ãƒãƒƒã‚¸ã‚·ã‚¹ãƒ†ãƒ 
        
        ã‚¿ãƒ¼ã‚²ãƒƒãƒˆå¸‚å ´ï¼š
        - ä¸­å­¦ç”Ÿãƒ»é«˜æ ¡ç”Ÿï¼ˆä¸»è¦ã‚¿ãƒ¼ã‚²ãƒƒãƒˆï¼‰
        - å¤§å­¦å—é¨“ç”Ÿ
        - è³‡æ ¼è©¦é¨“å—é¨“è€…
        
        åç›Šãƒ¢ãƒ‡ãƒ«ï¼š
        - ãƒ•ãƒªãƒ¼ãƒŸã‚¢ãƒ ï¼ˆåŸºæœ¬æ©Ÿèƒ½ç„¡æ–™ã€é«˜åº¦æ©Ÿèƒ½æœ‰æ–™ï¼‰
        - æœˆé¡ã‚µãƒ–ã‚¹ã‚¯ãƒªãƒ—ã‚·ãƒ§ãƒ³
        - ä¼æ¥­å‘ã‘ãƒ©ã‚¤ã‚»ãƒ³ã‚¹
        """

        voting_result = parallel_system.voting_quality_assessment(
            content=sample_content,
            assessment_criteria="ãƒ“ã‚¸ãƒã‚¹ææ¡ˆæ›¸ã®å“è³ª",
            num_votes=4,
        )

        print("\nğŸ“Š æŠ•ç¥¨è©•ä¾¡çµæœ:")
        print(f"- è©•ä¾¡è€…æ•°: {voting_result['num_evaluators']}")
        print(f"- æˆåŠŸè©•ä¾¡æ•°: {voting_result['successful_evaluations']}")
        print(f"- å®Ÿè¡Œæ™‚é–“: {voting_result['total_execution_time']:.2f}ç§’")
        print(f"\næœ€çµ‚è©•ä¾¡:\n{voting_result['final_assessment'][:200]}...\n")

        # ===== ãƒ‡ãƒ¢3: ä¸¦åˆ—ã‚³ãƒ¼ãƒ‰ãƒ¬ãƒ“ãƒ¥ãƒ¼ =====
        print("ğŸ‘¥ ãƒ‡ãƒ¢3: è¤‡æ•°å°‚é–€å®¶ã«ã‚ˆã‚‹ä¸¦åˆ—ã‚³ãƒ¼ãƒ‰ãƒ¬ãƒ“ãƒ¥ãƒ¼")
        print("-" * 60)

        sample_code = """
def user_login(username, password):
    # ãƒ¦ãƒ¼ã‚¶ãƒ¼èªè¨¼ã‚·ã‚¹ãƒ†ãƒ 
    import sqlite3
    
    # ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹æ¥ç¶š
    conn = sqlite3.connect('users.db')
    cursor = conn.cursor()
    
    # SQL ã‚¯ã‚¨ãƒªå®Ÿè¡Œ
    query = f"SELECT * FROM users WHERE username = '{username}' AND password = '{password}'"
    cursor.execute(query)
    result = cursor.fetchone()
    
    if result:
        # ãƒ­ã‚°ã‚¤ãƒ³æˆåŠŸ
        session_token = username + "_" + str(datetime.now())
        return {"status": "success", "token": session_token}
    else:
        # ãƒ­ã‚°ã‚¤ãƒ³å¤±æ•—
        return {"status": "failed"}
    
    conn.close()

def get_user_data(user_id):
    # ãƒ¦ãƒ¼ã‚¶ãƒ¼ãƒ‡ãƒ¼ã‚¿å–å¾—
    conn = sqlite3.connect('users.db')
    cursor = conn.cursor()
    
    query = f"SELECT * FROM user_data WHERE id = {user_id}"
    result = cursor.execute(query).fetchall()
    
    return result
        """

        code_review_result = parallel_system.parallel_code_review(
            code=sample_code, num_reviewers=3
        )

        print("\nğŸ“Š ã‚³ãƒ¼ãƒ‰ãƒ¬ãƒ“ãƒ¥ãƒ¼çµæœ:")
        print(f"- ãƒ¬ãƒ“ãƒ¥ã‚¢ãƒ¼æ•°: {code_review_result['num_reviewers']}")
        print(f"- æˆåŠŸãƒ¬ãƒ“ãƒ¥ãƒ¼æ•°: {code_review_result['successful_reviews']}")
        print(f"- å®Ÿè¡Œæ™‚é–“: {code_review_result['total_execution_time']:.2f}ç§’")
        print(f"\nçµ±åˆãƒ¬ãƒ“ãƒ¥ãƒ¼:\n{code_review_result['integrated_review'][:300]}...\n")

        # ===== ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹çµ±è¨ˆã®è¡¨ç¤º =====
        print("ğŸ“ˆ ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹çµ±è¨ˆ")
        print("-" * 30)
        stats = parallel_system.get_performance_statistics()
        print(f"ç·å®Ÿè¡Œå›æ•°: {stats['total_executions']}")
        print(f"ç·å®Ÿè¡Œæ™‚é–“: {stats['total_time']:.2f}ç§’")
        print(f"å¹³å‡å®Ÿè¡Œæ™‚é–“: {stats['average_execution_time']:.2f}ç§’")

        print("\nãƒ‘ã‚¿ãƒ¼ãƒ³åˆ¥çµ±è¨ˆ:")
        for pattern, data in stats["pattern_statistics"].items():
            print(f"  - {pattern}: {data['count']}å›, å¹³å‡{data['avg_time']:.2f}ç§’")

    finally:
        # ===== ãƒªã‚½ãƒ¼ã‚¹ã®ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ— =====
        parallel_system.cleanup()


if __name__ == "__main__":
    main()
