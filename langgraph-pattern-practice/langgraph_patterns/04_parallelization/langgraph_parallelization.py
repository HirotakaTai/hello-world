#!/usr/bin/env python
# -*- coding: utf-8 -*-
"""
LangGraphç‰ˆ Parallelization Pattern
LangGraphã‚’ä½¿ç”¨ã—ã¦ã‚¿ã‚¹ã‚¯ã‚’ä¸¦åˆ—å®Ÿè¡Œã—ã€åŠ¹ç‡çš„ãªå‡¦ç†ã‚’å®Ÿç¾ã™ã‚‹ãƒ‘ã‚¿ãƒ¼ãƒ³
"""

import asyncio
import datetime
from typing import Any
from typing import Dict
from typing import List
from typing import TypedDict

from dotenv import load_dotenv
from langchain_core.messages import HumanMessage
from langchain_core.prompts import ChatPromptTemplate

# LangChainé–¢é€£ã®ã‚¤ãƒ³ãƒãƒ¼ãƒˆ
from langchain_openai import ChatOpenAI
from langgraph.graph import END

# LangGraphé–¢é€£ã®ã‚¤ãƒ³ãƒãƒ¼ãƒˆ
from langgraph.graph import StateGraph

# ===== ç’°å¢ƒå¤‰æ•°ã®èª­ã¿è¾¼ã¿ =====
load_dotenv()

# ===== çŠ¶æ…‹å®šç¾© =====


class ParallelizationState(TypedDict):
    """ä¸¦åˆ—å‡¦ç†ãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼ã®çŠ¶æ…‹å®šç¾©"""

    input_text: str  # å…¥åŠ›ãƒ†ã‚­ã‚¹ãƒˆ
    text_sections: List[str]  # ãƒ†ã‚­ã‚¹ãƒˆã‚»ã‚¯ã‚·ãƒ§ãƒ³ï¼ˆåˆ†å‰²å¾Œï¼‰
    parallel_results: Dict[str, Any]  # ä¸¦åˆ—å‡¦ç†çµæœ
    final_summary: str  # æœ€çµ‚ã‚µãƒãƒªãƒ¼
    execution_log: List[str]  # å®Ÿè¡Œãƒ­ã‚°
    processing_type: str  # å‡¦ç†ã‚¿ã‚¤ãƒ—ï¼ˆsectioning, voting, reviewï¼‰


# ===== LangGraphãƒ™ãƒ¼ã‚¹ã®Parallelizationã‚¯ãƒ©ã‚¹ =====


class LangGraphParallelization:
    """LangGraphã‚’ä½¿ç”¨ã—ãŸä¸¦åˆ—å‡¦ç†ã‚·ã‚¹ãƒ†ãƒ """

    def __init__(self):
        """ä¸¦åˆ—å‡¦ç†ã‚·ã‚¹ãƒ†ãƒ ã®åˆæœŸåŒ–"""
        print("âš¡ LangGraphç‰ˆ Parallelizationã‚·ã‚¹ãƒ†ãƒ ã‚’åˆæœŸåŒ–ä¸­...")

        # OpenAI ChatLLMãƒ¢ãƒ‡ãƒ«ã‚’åˆæœŸåŒ–
        self.llm = ChatOpenAI(model="gpt-3.5-turbo", temperature=0.3, verbose=True)

        # ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆã‚’è¨­å®š
        self._setup_prompts()

        # å„å‡¦ç†ã‚¿ã‚¤ãƒ—ç”¨ã®LangGraphãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼ã‚’æ§‹ç¯‰
        self.sectioning_graph = self._build_sectioning_graph()
        self.voting_graph = self._build_voting_graph()
        self.review_graph = self._build_review_graph()

        print("âœ… ä¸¦åˆ—å‡¦ç†ã‚·ã‚¹ãƒ†ãƒ ã®åˆæœŸåŒ–ãŒå®Œäº†ã—ã¾ã—ãŸï¼")

    def _setup_prompts(self):
        """å„å‡¦ç†ç”¨ã®ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆã‚’è¨­å®š"""

        # ãƒ†ã‚­ã‚¹ãƒˆåˆ†å‰²ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ
        self.section_split_prompt = ChatPromptTemplate.from_template(
            """ä»¥ä¸‹ã®ãƒ†ã‚­ã‚¹ãƒˆã‚’è«–ç†çš„ãª3ã¤ã®ã‚»ã‚¯ã‚·ãƒ§ãƒ³ã«åˆ†å‰²ã—ã¦ãã ã•ã„ã€‚å„ã‚»ã‚¯ã‚·ãƒ§ãƒ³ã¯ç‹¬ç«‹ã—ã¦ç†è§£ã§ãã‚‹ã‚ˆã†ã«ã—ã¦ãã ã•ã„ã€‚

å…¥åŠ›ãƒ†ã‚­ã‚¹ãƒˆ:
{input_text}

åˆ†å‰²çµæœã‚’ä»¥ä¸‹ã®å½¢å¼ã§å‡ºåŠ›ã—ã¦ãã ã•ã„:
=== ã‚»ã‚¯ã‚·ãƒ§ãƒ³1 ===
[ã‚»ã‚¯ã‚·ãƒ§ãƒ³1ã®å†…å®¹]

=== ã‚»ã‚¯ã‚·ãƒ§ãƒ³2 ===
[ã‚»ã‚¯ã‚·ãƒ§ãƒ³2ã®å†…å®¹]

=== ã‚»ã‚¯ã‚·ãƒ§ãƒ³3 ===
[ã‚»ã‚¯ã‚·ãƒ§ãƒ³3ã®å†…å®¹]
"""
        )

        # ã‚»ã‚¯ã‚·ãƒ§ãƒ³è¦ç´„ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ
        self.section_summary_prompt = ChatPromptTemplate.from_template(
            """ä»¥ä¸‹ã®ãƒ†ã‚­ã‚¹ãƒˆã‚»ã‚¯ã‚·ãƒ§ãƒ³ã‚’ç°¡æ½”ã«è¦ç´„ã—ã¦ãã ã•ã„ã€‚é‡è¦ãªãƒã‚¤ãƒ³ãƒˆã‚’3-5ã¤ã®ç®‡æ¡æ›¸ãã§ç¤ºã—ã¦ãã ã•ã„ã€‚

ã‚»ã‚¯ã‚·ãƒ§ãƒ³å†…å®¹:
{section_text}

è¦ç´„çµæœã‚’ç®‡æ¡æ›¸ãå½¢å¼ã§å‡ºåŠ›ã—ã¦ãã ã•ã„ã€‚
"""
        )

        # æŠ•ç¥¨ç”¨è©•ä¾¡ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ
        self.voting_evaluation_prompt = ChatPromptTemplate.from_template(
            """ã‚ãªãŸã¯{evaluator_type}ã®å°‚é–€å®¶ã§ã™ã€‚ä»¥ä¸‹ã®ææ¡ˆã‚’è©•ä¾¡ã—ã¦ãã ã•ã„ã€‚

ææ¡ˆå†…å®¹:
{proposal_text}

è©•ä¾¡åŸºæº–:
{evaluation_criteria}

ä»¥ä¸‹ã®å½¢å¼ã§è©•ä¾¡ã—ã¦ãã ã•ã„:
ã‚¹ã‚³ã‚¢: [1-10]
è©•ä¾¡ç†ç”±: [è©•ä¾¡ã®è©³ç´°ãªç†ç”±]
æ”¹å–„ææ¡ˆ: [å…·ä½“çš„ãªæ”¹å–„æ¡ˆãŒã‚ã‚Œã°]
"""
        )

        # ã‚³ãƒ¼ãƒ‰ãƒ¬ãƒ“ãƒ¥ãƒ¼ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ
        self.code_review_prompt = ChatPromptTemplate.from_template(
            """ã‚ãªãŸã¯{reviewer_type}ã®å°‚é–€å®¶ã§ã™ã€‚ä»¥ä¸‹ã®ã‚³ãƒ¼ãƒ‰ã‚’ãƒ¬ãƒ“ãƒ¥ãƒ¼ã—ã¦ãã ã•ã„ã€‚

ã‚³ãƒ¼ãƒ‰:
{code_text}

ãƒ¬ãƒ“ãƒ¥ãƒ¼è¦³ç‚¹:
{review_criteria}

ä»¥ä¸‹ã®å½¢å¼ã§ãƒ¬ãƒ“ãƒ¥ãƒ¼ã—ã¦ãã ã•ã„:
è©•ä¾¡: [Good/Needs Improvement/Critical Issues]
æŒ‡æ‘˜äº‹é …: [å…·ä½“çš„ãªå•é¡Œç‚¹]
æ¨å¥¨äº‹é …: [æ”¹å–„ææ¡ˆ]
"""
        )

        # çµ±åˆã‚µãƒãƒªãƒ¼ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ
        self.integration_prompt = ChatPromptTemplate.from_template(
            """ä»¥ä¸‹ã®ä¸¦åˆ—å‡¦ç†çµæœã‚’çµ±åˆã—ã¦ã€åŒ…æ‹¬çš„ãªã‚µãƒãƒªãƒ¼ã‚’ä½œæˆã—ã¦ãã ã•ã„ã€‚

å‡¦ç†ã‚¿ã‚¤ãƒ—: {processing_type}
ä¸¦åˆ—å‡¦ç†çµæœ:
{parallel_results}

çµ±åˆçµæœã¨ã—ã¦ã€ä»¥ä¸‹ã‚’å«ã‚€ã‚µãƒãƒªãƒ¼ã‚’ä½œæˆã—ã¦ãã ã•ã„:
1. å…¨ä½“çš„ãªæ¦‚è¦
2. é‡è¦ãªç™ºè¦‹ã‚„æ´å¯Ÿ
3. å…±é€šã™ã‚‹ãƒ†ãƒ¼ãƒã‚„ãƒ‘ã‚¿ãƒ¼ãƒ³
4. çµè«–ã¨æ¨å¥¨äº‹é …
"""
        )

    def _build_sectioning_graph(self) -> StateGraph:
        """ã‚»ã‚¯ã‚·ãƒ§ãƒ‹ãƒ³ã‚°ï¼ˆæ–‡æ›¸åˆ†å‰²å‡¦ç†ï¼‰ã®ãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼ã‚’æ§‹ç¯‰"""
        print("ğŸ”§ ã‚»ã‚¯ã‚·ãƒ§ãƒ‹ãƒ³ã‚°ãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼ã‚’æ§‹ç¯‰ä¸­...")

        workflow = StateGraph(ParallelizationState)

        # ãƒãƒ¼ãƒ‰ã‚’è¿½åŠ 
        workflow.add_node("split_text", self._split_text)
        workflow.add_node("summarize_sections", self._summarize_sections_parallel)
        workflow.add_node("integrate_summaries", self._integrate_summaries)

        # ã‚¨ãƒ³ãƒˆãƒªãƒ¼ãƒã‚¤ãƒ³ãƒˆã¨çµŒè·¯è¨­å®š
        workflow.set_entry_point("split_text")
        workflow.add_edge("split_text", "summarize_sections")
        workflow.add_edge("summarize_sections", "integrate_summaries")
        workflow.add_edge("integrate_summaries", END)

        return workflow.compile()

    def _build_voting_graph(self) -> StateGraph:
        """æŠ•ç¥¨ï¼ˆè¤‡æ•°è©•ä¾¡è€…ã«ã‚ˆã‚‹è©•ä¾¡ï¼‰ã®ãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼ã‚’æ§‹ç¯‰"""
        print("ğŸ”§ æŠ•ç¥¨ãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼ã‚’æ§‹ç¯‰ä¸­...")

        workflow = StateGraph(ParallelizationState)

        # ãƒãƒ¼ãƒ‰ã‚’è¿½åŠ 
        workflow.add_node("evaluate_parallel", self._evaluate_parallel)
        workflow.add_node("aggregate_votes", self._aggregate_votes)

        # ã‚¨ãƒ³ãƒˆãƒªãƒ¼ãƒã‚¤ãƒ³ãƒˆã¨çµŒè·¯è¨­å®š
        workflow.set_entry_point("evaluate_parallel")
        workflow.add_edge("evaluate_parallel", "aggregate_votes")
        workflow.add_edge("aggregate_votes", END)

        return workflow.compile()

    def _build_review_graph(self) -> StateGraph:
        """ãƒ¬ãƒ“ãƒ¥ãƒ¼ï¼ˆè¤‡æ•°ãƒ¬ãƒ“ãƒ¥ã‚¢ãƒ¼ã«ã‚ˆã‚‹ã‚³ãƒ¼ãƒ‰ãƒ¬ãƒ“ãƒ¥ãƒ¼ï¼‰ã®ãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼ã‚’æ§‹ç¯‰"""
        print("ğŸ”§ ãƒ¬ãƒ“ãƒ¥ãƒ¼ãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼ã‚’æ§‹ç¯‰ä¸­...")

        workflow = StateGraph(ParallelizationState)

        # ãƒãƒ¼ãƒ‰ã‚’è¿½åŠ 
        workflow.add_node("review_parallel", self._review_parallel)
        workflow.add_node("consolidate_reviews", self._consolidate_reviews)

        # ã‚¨ãƒ³ãƒˆãƒªãƒ¼ãƒã‚¤ãƒ³ãƒˆã¨çµŒè·¯è¨­å®š
        workflow.set_entry_point("review_parallel")
        workflow.add_edge("review_parallel", "consolidate_reviews")
        workflow.add_edge("consolidate_reviews", END)

        return workflow.compile()

    # ===== ã‚»ã‚¯ã‚·ãƒ§ãƒ‹ãƒ³ã‚°é–¢é€£ã®å‡¦ç†ãƒ¡ã‚½ãƒƒãƒ‰ =====

    def _split_text(self, state: ParallelizationState) -> Dict[str, Any]:
        """ãƒ†ã‚­ã‚¹ãƒˆã‚’è¤‡æ•°ã®ã‚»ã‚¯ã‚·ãƒ§ãƒ³ã«åˆ†å‰²"""
        print("âœ‚ï¸  ãƒ†ã‚­ã‚¹ãƒˆåˆ†å‰²å‡¦ç†ä¸­...")

        input_text = state["input_text"]

        # ãƒ†ã‚­ã‚¹ãƒˆåˆ†å‰²ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’ç”Ÿæˆ
        prompt = self.section_split_prompt.format(input_text=input_text)

        # LLMã‚’å‘¼ã³å‡ºã—
        response = self.llm.invoke([HumanMessage(content=prompt)])
        split_result = response.content

        # ã‚»ã‚¯ã‚·ãƒ§ãƒ³ã‚’æŠ½å‡ºï¼ˆç°¡æ˜“ãƒ‘ãƒ¼ã‚µãƒ¼ï¼‰
        sections = []
        current_section = ""
        for line in split_result.split("\n"):
            if line.startswith("=== ã‚»ã‚¯ã‚·ãƒ§ãƒ³"):
                if current_section.strip():
                    sections.append(current_section.strip())
                current_section = ""
            else:
                current_section += line + "\n"

        if current_section.strip():
            sections.append(current_section.strip())

        # å®Ÿè¡Œãƒ­ã‚°ã‚’æ›´æ–°
        log_entry = f"[{datetime.datetime.now().strftime('%H:%M:%S')}] ãƒ†ã‚­ã‚¹ãƒˆåˆ†å‰²å®Œäº†: {len(sections)}ã‚»ã‚¯ã‚·ãƒ§ãƒ³"
        execution_log = state.get("execution_log", [])
        execution_log.append(log_entry)

        print(f"âœ… ãƒ†ã‚­ã‚¹ãƒˆåˆ†å‰²å®Œäº†: {len(sections)}å€‹ã®ã‚»ã‚¯ã‚·ãƒ§ãƒ³")

        return {"text_sections": sections, "execution_log": execution_log}

    def _summarize_sections_parallel(
        self, state: ParallelizationState
    ) -> Dict[str, Any]:
        """è¤‡æ•°ã®ã‚»ã‚¯ã‚·ãƒ§ãƒ³ã‚’ä¸¦åˆ—ã§è¦ç´„"""
        print("ğŸ“ ã‚»ã‚¯ã‚·ãƒ§ãƒ³ä¸¦åˆ—è¦ç´„å‡¦ç†ä¸­...")

        sections = state["text_sections"]

        # å„ã‚»ã‚¯ã‚·ãƒ§ãƒ³ã‚’ä¸¦åˆ—ã§è¦ç´„
        async def summarize_section_async(section_idx: int, section_text: str) -> tuple:
            """å˜ä¸€ã‚»ã‚¯ã‚·ãƒ§ãƒ³ã®éåŒæœŸè¦ç´„"""
            prompt = self.section_summary_prompt.format(section_text=section_text)
            response = self.llm.invoke([HumanMessage(content=prompt)])
            return section_idx, response.content

        async def process_all_sections():
            """å…¨ã‚»ã‚¯ã‚·ãƒ§ãƒ³ã®ä¸¦åˆ—å‡¦ç†"""
            tasks = [
                summarize_section_async(i, section)
                for i, section in enumerate(sections)
            ]
            return await asyncio.gather(*tasks)

        # ä¸¦åˆ—å‡¦ç†ã‚’å®Ÿè¡Œ
        try:
            # æ–°ã—ã„ã‚¤ãƒ™ãƒ³ãƒˆãƒ«ãƒ¼ãƒ—ã‚’ä½œæˆã—ã¦å®Ÿè¡Œ
            loop = asyncio.new_event_loop()
            asyncio.set_event_loop(loop)
            section_summaries = loop.run_until_complete(process_all_sections())
            loop.close()
        except Exception as e:
            print(f"âš ï¸  ä¸¦åˆ—å‡¦ç†ã§ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã€é †æ¬¡å‡¦ç†ã«åˆ‡ã‚Šæ›¿ãˆ: {e}")
            # ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯: é †æ¬¡å‡¦ç†
            section_summaries = []
            for i, section in enumerate(sections):
                prompt = self.section_summary_prompt.format(section_text=section)
                response = self.llm.invoke([HumanMessage(content=prompt)])
                section_summaries.append((i, response.content))

        # çµæœã‚’æ•´ç†
        parallel_results = {
            f"section_{idx}": summary for idx, summary in section_summaries
        }

        # å®Ÿè¡Œãƒ­ã‚°ã‚’æ›´æ–°
        log_entry = f"[{datetime.datetime.now().strftime('%H:%M:%S')}] ã‚»ã‚¯ã‚·ãƒ§ãƒ³ä¸¦åˆ—è¦ç´„å®Œäº†: {len(parallel_results)}ä»¶"
        execution_log = state["execution_log"]
        execution_log.append(log_entry)

        print(f"âœ… ã‚»ã‚¯ã‚·ãƒ§ãƒ³ä¸¦åˆ—è¦ç´„å®Œäº†: {len(parallel_results)}ä»¶")

        return {"parallel_results": parallel_results, "execution_log": execution_log}

    def _integrate_summaries(self, state: ParallelizationState) -> Dict[str, Any]:
        """è¦ç´„çµæœã‚’çµ±åˆ"""
        print("ğŸ”— è¦ç´„çµ±åˆå‡¦ç†ä¸­...")

        parallel_results = state["parallel_results"]

        # çµ±åˆãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’ç”Ÿæˆ
        results_text = "\n".join(
            [
                f"ã‚»ã‚¯ã‚·ãƒ§ãƒ³{i}: {summary}"
                for i, summary in enumerate(parallel_results.values())
            ]
        )

        prompt = self.integration_prompt.format(
            processing_type="ã‚»ã‚¯ã‚·ãƒ§ãƒ³è¦ç´„", parallel_results=results_text
        )

        # LLMã‚’å‘¼ã³å‡ºã—
        response = self.llm.invoke([HumanMessage(content=prompt)])
        final_summary = response.content

        # å®Ÿè¡Œãƒ­ã‚°ã‚’æ›´æ–°
        log_entry = f"[{datetime.datetime.now().strftime('%H:%M:%S')}] è¦ç´„çµ±åˆå®Œäº†"
        execution_log = state["execution_log"]
        execution_log.append(log_entry)

        print("âœ… è¦ç´„çµ±åˆå®Œäº†")

        return {"final_summary": final_summary, "execution_log": execution_log}

    # ===== æŠ•ç¥¨é–¢é€£ã®å‡¦ç†ãƒ¡ã‚½ãƒƒãƒ‰ =====

    def _evaluate_parallel(self, state: ParallelizationState) -> Dict[str, Any]:
        """è¤‡æ•°ã®è©•ä¾¡è€…ã«ã‚ˆã‚‹ä¸¦åˆ—è©•ä¾¡"""
        print("ğŸ—³ï¸  ä¸¦åˆ—è©•ä¾¡å‡¦ç†ä¸­...")

        input_text = state["input_text"]

        # è©•ä¾¡è€…ã‚¿ã‚¤ãƒ—ã¨è©•ä¾¡åŸºæº–ã‚’å®šç¾©
        evaluators = [
            {"type": "æŠ€è¡“å°‚é–€å®¶", "criteria": "æŠ€è¡“çš„å®Ÿç¾æ€§ã€å®Ÿè£…ã®è¤‡é›‘ã•ã€ä¿å®ˆæ€§"},
            {"type": "ãƒ“ã‚¸ãƒã‚¹å°‚é–€å®¶", "criteria": "ãƒ“ã‚¸ãƒã‚¹ä¾¡å€¤ã€ROIã€å¸‚å ´é©åˆæ€§"},
            {
                "type": "ãƒ¦ãƒ¼ã‚¶ãƒ¼ä½“é¨“å°‚é–€å®¶",
                "criteria": "ä½¿ã„ã‚„ã™ã•ã€ã‚¢ã‚¯ã‚»ã‚·ãƒ“ãƒªãƒ†ã‚£ã€ãƒ¦ãƒ¼ã‚¶ãƒ¼ã‚¤ãƒ³ãƒ‘ã‚¯ãƒˆ",
            },
        ]

        # å„è©•ä¾¡è€…ã«ã‚ˆã‚‹ä¸¦åˆ—è©•ä¾¡
        async def evaluate_async(evaluator: dict) -> tuple:
            """å˜ä¸€è©•ä¾¡è€…ã«ã‚ˆã‚‹éåŒæœŸè©•ä¾¡"""
            prompt = self.voting_evaluation_prompt.format(
                evaluator_type=evaluator["type"],
                proposal_text=input_text,
                evaluation_criteria=evaluator["criteria"],
            )
            response = self.llm.invoke([HumanMessage(content=prompt)])
            return evaluator["type"], response.content

        async def process_all_evaluations():
            """å…¨è©•ä¾¡è€…ã«ã‚ˆã‚‹ä¸¦åˆ—å‡¦ç†"""
            tasks = [evaluate_async(evaluator) for evaluator in evaluators]
            return await asyncio.gather(*tasks)

        # ä¸¦åˆ—å‡¦ç†ã‚’å®Ÿè¡Œ
        try:
            loop = asyncio.new_event_loop()
            asyncio.set_event_loop(loop)
            evaluations = loop.run_until_complete(process_all_evaluations())
            loop.close()
        except Exception:
            # ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯: é †æ¬¡å‡¦ç†
            evaluations = []
            for evaluator in evaluators:
                prompt = self.voting_evaluation_prompt.format(
                    evaluator_type=evaluator["type"],
                    proposal_text=input_text,
                    evaluation_criteria=evaluator["criteria"],
                )
                response = self.llm.invoke([HumanMessage(content=prompt)])
                evaluations.append((evaluator["type"], response.content))

        # çµæœã‚’æ•´ç†
        parallel_results = {
            evaluator_type: evaluation for evaluator_type, evaluation in evaluations
        }

        # å®Ÿè¡Œãƒ­ã‚°ã‚’æ›´æ–°
        log_entry = f"[{datetime.datetime.now().strftime('%H:%M:%S')}] ä¸¦åˆ—è©•ä¾¡å®Œäº†: {len(parallel_results)}åã®è©•ä¾¡è€…"
        execution_log = state.get("execution_log", [])
        execution_log.append(log_entry)

        print(f"âœ… ä¸¦åˆ—è©•ä¾¡å®Œäº†: {len(parallel_results)}åã®è©•ä¾¡è€…")

        return {"parallel_results": parallel_results, "execution_log": execution_log}

    def _aggregate_votes(self, state: ParallelizationState) -> Dict[str, Any]:
        """æŠ•ç¥¨çµæœã‚’é›†ç´„"""
        print("ğŸ“Š æŠ•ç¥¨é›†ç´„å‡¦ç†ä¸­...")

        parallel_results = state["parallel_results"]

        # é›†ç´„ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’ç”Ÿæˆ
        results_text = "\n".join(
            [
                f"{evaluator}: {evaluation}"
                for evaluator, evaluation in parallel_results.items()
            ]
        )

        prompt = self.integration_prompt.format(
            processing_type="è¤‡æ•°è©•ä¾¡è€…ã«ã‚ˆã‚‹æŠ•ç¥¨", parallel_results=results_text
        )

        # LLMã‚’å‘¼ã³å‡ºã—
        response = self.llm.invoke([HumanMessage(content=prompt)])
        final_summary = response.content

        # å®Ÿè¡Œãƒ­ã‚°ã‚’æ›´æ–°
        log_entry = f"[{datetime.datetime.now().strftime('%H:%M:%S')}] æŠ•ç¥¨é›†ç´„å®Œäº†"
        execution_log = state["execution_log"]
        execution_log.append(log_entry)

        print("âœ… æŠ•ç¥¨é›†ç´„å®Œäº†")

        return {"final_summary": final_summary, "execution_log": execution_log}

    # ===== ãƒ¬ãƒ“ãƒ¥ãƒ¼é–¢é€£ã®å‡¦ç†ãƒ¡ã‚½ãƒƒãƒ‰ =====

    def _review_parallel(self, state: ParallelizationState) -> Dict[str, Any]:
        """è¤‡æ•°ã®ãƒ¬ãƒ“ãƒ¥ã‚¢ãƒ¼ã«ã‚ˆã‚‹ä¸¦åˆ—ã‚³ãƒ¼ãƒ‰ãƒ¬ãƒ“ãƒ¥ãƒ¼"""
        print("ğŸ‘¥ ä¸¦åˆ—ã‚³ãƒ¼ãƒ‰ãƒ¬ãƒ“ãƒ¥ãƒ¼å‡¦ç†ä¸­...")

        input_text = state["input_text"]

        # ãƒ¬ãƒ“ãƒ¥ã‚¢ãƒ¼ã‚¿ã‚¤ãƒ—ã¨ãƒ¬ãƒ“ãƒ¥ãƒ¼åŸºæº–ã‚’å®šç¾©
        reviewers = [
            {
                "type": "ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£ã‚¨ãƒ³ã‚¸ãƒ‹ã‚¢",
                "criteria": "ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£è„†å¼±æ€§ã€èªè¨¼ãƒ»èªå¯ã€ãƒ‡ãƒ¼ã‚¿ä¿è­·",
            },
            {
                "type": "ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ã‚¨ãƒ³ã‚¸ãƒ‹ã‚¢",
                "criteria": "å®Ÿè¡ŒåŠ¹ç‡ã€ãƒ¡ãƒ¢ãƒªä½¿ç”¨é‡ã€ã‚¹ã‚±ãƒ¼ãƒ©ãƒ“ãƒªãƒ†ã‚£",
            },
            {
                "type": "ã‚³ãƒ¼ãƒ‰å“è³ªã‚¨ãƒ³ã‚¸ãƒ‹ã‚¢",
                "criteria": "å¯èª­æ€§ã€ä¿å®ˆæ€§ã€ãƒ†ã‚¹ãƒˆå®¹æ˜“æ€§ã€è¨­è¨ˆãƒ‘ã‚¿ãƒ¼ãƒ³",
            },
        ]

        # å„ãƒ¬ãƒ“ãƒ¥ã‚¢ãƒ¼ã«ã‚ˆã‚‹ä¸¦åˆ—ãƒ¬ãƒ“ãƒ¥ãƒ¼
        async def review_async(reviewer: dict) -> tuple:
            """å˜ä¸€ãƒ¬ãƒ“ãƒ¥ã‚¢ãƒ¼ã«ã‚ˆã‚‹éåŒæœŸãƒ¬ãƒ“ãƒ¥ãƒ¼"""
            prompt = self.code_review_prompt.format(
                reviewer_type=reviewer["type"],
                code_text=input_text,
                review_criteria=reviewer["criteria"],
            )
            response = self.llm.invoke([HumanMessage(content=prompt)])
            return reviewer["type"], response.content

        async def process_all_reviews():
            """å…¨ãƒ¬ãƒ“ãƒ¥ã‚¢ãƒ¼ã«ã‚ˆã‚‹ä¸¦åˆ—å‡¦ç†"""
            tasks = [review_async(reviewer) for reviewer in reviewers]
            return await asyncio.gather(*tasks)

        # ä¸¦åˆ—å‡¦ç†ã‚’å®Ÿè¡Œ
        try:
            loop = asyncio.new_event_loop()
            asyncio.set_event_loop(loop)
            reviews = loop.run_until_complete(process_all_reviews())
            loop.close()
        except Exception:
            # ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯: é †æ¬¡å‡¦ç†
            reviews = []
            for reviewer in reviewers:
                prompt = self.code_review_prompt.format(
                    reviewer_type=reviewer["type"],
                    code_text=input_text,
                    review_criteria=reviewer["criteria"],
                )
                response = self.llm.invoke([HumanMessage(content=prompt)])
                reviews.append((reviewer["type"], response.content))

        # çµæœã‚’æ•´ç†
        parallel_results = {reviewer_type: review for reviewer_type, review in reviews}

        # å®Ÿè¡Œãƒ­ã‚°ã‚’æ›´æ–°
        log_entry = f"[{datetime.datetime.now().strftime('%H:%M:%S')}] ä¸¦åˆ—ãƒ¬ãƒ“ãƒ¥ãƒ¼å®Œäº†: {len(parallel_results)}åã®ãƒ¬ãƒ“ãƒ¥ã‚¢ãƒ¼"
        execution_log = state.get("execution_log", [])
        execution_log.append(log_entry)

        print(f"âœ… ä¸¦åˆ—ãƒ¬ãƒ“ãƒ¥ãƒ¼å®Œäº†: {len(parallel_results)}åã®ãƒ¬ãƒ“ãƒ¥ã‚¢ãƒ¼")

        return {"parallel_results": parallel_results, "execution_log": execution_log}

    def _consolidate_reviews(self, state: ParallelizationState) -> Dict[str, Any]:
        """ãƒ¬ãƒ“ãƒ¥ãƒ¼çµæœã‚’çµ±åˆ"""
        print("ğŸ“‹ ãƒ¬ãƒ“ãƒ¥ãƒ¼çµ±åˆå‡¦ç†ä¸­...")

        parallel_results = state["parallel_results"]

        # çµ±åˆãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’ç”Ÿæˆ
        results_text = "\n".join(
            [f"{reviewer}: {review}" for reviewer, review in parallel_results.items()]
        )

        prompt = self.integration_prompt.format(
            processing_type="è¤‡æ•°ãƒ¬ãƒ“ãƒ¥ã‚¢ãƒ¼ã«ã‚ˆã‚‹ã‚³ãƒ¼ãƒ‰ãƒ¬ãƒ“ãƒ¥ãƒ¼",
            parallel_results=results_text,
        )

        # LLMã‚’å‘¼ã³å‡ºã—
        response = self.llm.invoke([HumanMessage(content=prompt)])
        final_summary = response.content

        # å®Ÿè¡Œãƒ­ã‚°ã‚’æ›´æ–°
        log_entry = f"[{datetime.datetime.now().strftime('%H:%M:%S')}] ãƒ¬ãƒ“ãƒ¥ãƒ¼çµ±åˆå®Œäº†"
        execution_log = state["execution_log"]
        execution_log.append(log_entry)

        print("âœ… ãƒ¬ãƒ“ãƒ¥ãƒ¼çµ±åˆå®Œäº†")

        return {"final_summary": final_summary, "execution_log": execution_log}

    # ===== ãƒ¡ã‚¤ãƒ³å‡¦ç†ãƒ¡ã‚½ãƒƒãƒ‰ =====

    def process_sectioning(self, input_text: str) -> Dict[str, Any]:
        """ã‚»ã‚¯ã‚·ãƒ§ãƒ‹ãƒ³ã‚°ï¼ˆæ–‡æ›¸åˆ†å‰²ï¼‰å‡¦ç†"""
        return self._execute_workflow(
            self.sectioning_graph, input_text, "ã‚»ã‚¯ã‚·ãƒ§ãƒ‹ãƒ³ã‚°"
        )

    def process_voting(self, input_text: str) -> Dict[str, Any]:
        """æŠ•ç¥¨ï¼ˆè¤‡æ•°è©•ä¾¡è€…ã«ã‚ˆã‚‹è©•ä¾¡ï¼‰å‡¦ç†"""
        return self._execute_workflow(self.voting_graph, input_text, "æŠ•ç¥¨")

    def process_review(self, input_text: str) -> Dict[str, Any]:
        """ãƒ¬ãƒ“ãƒ¥ãƒ¼ï¼ˆè¤‡æ•°ãƒ¬ãƒ“ãƒ¥ã‚¢ãƒ¼ã«ã‚ˆã‚‹ã‚³ãƒ¼ãƒ‰ãƒ¬ãƒ“ãƒ¥ãƒ¼ï¼‰å‡¦ç†"""
        return self._execute_workflow(self.review_graph, input_text, "ãƒ¬ãƒ“ãƒ¥ãƒ¼")

    def _execute_workflow(
        self, graph: StateGraph, input_text: str, processing_type: str
    ) -> Dict[str, Any]:
        """ãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼å®Ÿè¡Œã®å…±é€šå‡¦ç†"""
        print(f"âš¡ {processing_type}å‡¦ç†é–‹å§‹: {len(input_text)}æ–‡å­—")
        print("-" * 60)

        # åˆæœŸçŠ¶æ…‹ã‚’è¨­å®š
        initial_state = {
            "input_text": input_text,
            "text_sections": [],
            "parallel_results": {},
            "final_summary": "",
            "execution_log": [],
            "processing_type": processing_type,
        }

        # ãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼ã‚’å®Ÿè¡Œ
        start_time = datetime.datetime.now()
        result = graph.invoke(initial_state)
        end_time = datetime.datetime.now()

        # å®Ÿè¡Œæ™‚é–“ã‚’è¨ˆç®—
        execution_time = (end_time - start_time).total_seconds()

        print("-" * 60)
        print(f"ğŸ‰ {processing_type}å‡¦ç†å®Œäº†ï¼ (å®Ÿè¡Œæ™‚é–“: {execution_time:.2f}ç§’)")

        return {
            "input_text": result["input_text"],
            "processing_type": processing_type,
            "parallel_results": result["parallel_results"],
            "final_summary": result["final_summary"],
            "execution_log": result["execution_log"],
            "execution_time": execution_time,
        }


# ===== ãƒ‡ãƒ¢ç”¨ã®ãƒ¡ã‚¤ãƒ³é–¢æ•° =====


def main():
    """LangGraphç‰ˆ Parallelizationã®ãƒ‡ãƒ¢ãƒ³ã‚¹ãƒˆãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³"""
    print("=" * 60)
    print("âš¡ LangGraphç‰ˆ Parallelization Pattern ãƒ‡ãƒ¢")
    print("=" * 60)
    print("ã“ã®ãƒ‡ãƒ¢ã§ã¯ã€LangGraphã‚’ä½¿ç”¨ã—ã¦ã‚¿ã‚¹ã‚¯ã‚’ä¸¦åˆ—å®Ÿè¡Œã—ã¾ã™ã€‚")
    print("å‡¦ç†ã‚¿ã‚¤ãƒ—: ã‚»ã‚¯ã‚·ãƒ§ãƒ‹ãƒ³ã‚°ã€æŠ•ç¥¨ã€ã‚³ãƒ¼ãƒ‰ãƒ¬ãƒ“ãƒ¥ãƒ¼")
    print()

    try:
        # Parallelizationã‚·ã‚¹ãƒ†ãƒ ã‚’åˆæœŸåŒ–
        processor = LangGraphParallelization()

        # ãƒ‡ãƒ¢ç”¨ã®å…¥åŠ›ãƒ‡ãƒ¼ã‚¿
        demo_data = {
            "sectioning": """
äººå·¥çŸ¥èƒ½ï¼ˆAIï¼‰ã¯ç¾ä»£ç¤¾ä¼šã«ãŠã„ã¦æ€¥é€Ÿã«ç™ºå±•ã—ã¦ã„ã‚‹æŠ€è¡“åˆ†é‡ã§ã™ã€‚æ©Ÿæ¢°å­¦ç¿’ã€æ·±å±¤å­¦ç¿’ã€è‡ªç„¶è¨€èªå‡¦ç†ãªã©ã®æŠ€è¡“ãŒçµ±åˆã•ã‚Œã€æ§˜ã€…ãªç”£æ¥­åˆ†é‡ã§é©æ–°ã‚’ã‚‚ãŸã‚‰ã—ã¦ã„ã¾ã™ã€‚

AIã®å¿œç”¨åˆ†é‡ã¯åºƒç¯„å›²ã«ã‚ãŸã‚Šã¾ã™ã€‚åŒ»ç™‚åˆ†é‡ã§ã¯ç”»åƒè¨ºæ–­ã‚„è–¬ç‰©ç™ºè¦‹ã€è‡ªå‹•è»Šç”£æ¥­ã§ã¯è‡ªå‹•é‹è»¢æŠ€è¡“ã€é‡‘èåˆ†é‡ã§ã¯ä¸æ­£æ¤œçŸ¥ã‚„ã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ å–å¼•ãªã©ãŒä»£è¡¨ä¾‹ã§ã™ã€‚ã“ã‚Œã‚‰ã®æŠ€è¡“ã¯åŠ¹ç‡æ€§ã‚’å‘ä¸Šã•ã›ã€äººé–“ã®èƒ½åŠ›ã‚’æ‹¡å¼µã™ã‚‹å½¹å‰²ã‚’æœãŸã—ã¦ã„ã¾ã™ã€‚

ã—ã‹ã—ã€AIæŠ€è¡“ã®ç™ºå±•ã«ã¯èª²é¡Œã‚‚å­˜åœ¨ã—ã¾ã™ã€‚ãƒ—ãƒ©ã‚¤ãƒã‚·ãƒ¼ã®ä¿è­·ã€é›‡ç”¨ã¸ã®å½±éŸ¿ã€ã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ ã®åè¦‹ã€èª¬æ˜å¯èƒ½æ€§ãªã©ã®å•é¡ŒãŒè­°è«–ã•ã‚Œã¦ã„ã¾ã™ã€‚ã“ã‚Œã‚‰ã®èª²é¡Œã«å¯¾å‡¦ã™ã‚‹ãŸã‚ã€AIå€«ç†ã‚„ã‚¬ãƒãƒŠãƒ³ã‚¹ã®ç¢ºç«‹ãŒé‡è¦è¦–ã•ã‚Œã¦ã„ã¾ã™ã€‚å°†æ¥ã®AIç¤¾ä¼šã§ã¯ã€æŠ€è¡“ã®åˆ©ç›Šã‚’æœ€å¤§åŒ–ã—ãªãŒã‚‰ã€ãƒªã‚¹ã‚¯ã‚’æœ€å°åŒ–ã™ã‚‹ãƒãƒ©ãƒ³ã‚¹ã®å–ã‚ŒãŸã‚¢ãƒ—ãƒ­ãƒ¼ãƒãŒæ±‚ã‚ã‚‰ã‚Œã¾ã™ã€‚
            """.strip(),
            "voting": """
æ–°ã—ã„ãƒ¢ãƒã‚¤ãƒ«ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ã€ŒSmartLifeã€ã®é–‹ç™ºææ¡ˆã§ã™ã€‚ã“ã®ã‚¢ãƒ—ãƒªã¯ã€ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®æ—¥å¸¸ç”Ÿæ´»ã‚’åŠ¹ç‡åŒ–ã™ã‚‹ãŸã‚ã®ã‚ªãƒ¼ãƒ«ã‚¤ãƒ³ãƒ¯ãƒ³ã‚½ãƒªãƒ¥ãƒ¼ã‚·ãƒ§ãƒ³ã§ã™ã€‚ä¸»ãªæ©Ÿèƒ½ã¨ã—ã¦ã€ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ«ç®¡ç†ã€æ”¯å‡ºè¿½è·¡ã€å¥åº·ãƒ¢ãƒ‹ã‚¿ãƒªãƒ³ã‚°ã€ã‚¿ã‚¹ã‚¯ç®¡ç†ã‚’çµ±åˆã—ã€AIã‚’æ´»ç”¨ã—ã¦ãƒ‘ãƒ¼ã‚½ãƒŠãƒ©ã‚¤ã‚ºã•ã‚ŒãŸææ¡ˆã‚’è¡Œã„ã¾ã™ã€‚é–‹ç™ºæœŸé–“ã¯6ãƒ¶æœˆã€äºˆç®—ã¯500ä¸‡å††ã‚’äºˆå®šã—ã¦ã„ã¾ã™ã€‚
            """.strip(),
            "review": """
def user_authentication(username, password):
    # ãƒ¦ãƒ¼ã‚¶ãƒ¼èªè¨¼ã‚’è¡Œã†é–¢æ•°
    users_db = {"admin": "password123", "user": "12345"}
    
    if username in users_db:
        if users_db[username] == password:
            print(f"ãƒ­ã‚°ã‚¤ãƒ³æˆåŠŸ: {username}")
            return True
        else:
            print("ãƒ‘ã‚¹ãƒ¯ãƒ¼ãƒ‰ãŒé–“é•ã£ã¦ã„ã¾ã™")
            return False
    else:
        print("ãƒ¦ãƒ¼ã‚¶ãƒ¼ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")
        return False

def process_user_data(user_id):
    # ãƒ¦ãƒ¼ã‚¶ãƒ¼ãƒ‡ãƒ¼ã‚¿ã‚’å‡¦ç†ã™ã‚‹é–¢æ•°
    query = f"SELECT * FROM users WHERE id = {user_id}"
    # ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã‚¯ã‚¨ãƒªã‚’å®Ÿè¡Œï¼ˆå®Ÿè£…ã¯çœç•¥ï¼‰
    return query
            """.strip(),
        }

        # å„å‡¦ç†ã‚¿ã‚¤ãƒ—ã®ãƒ‡ãƒ¢å®Ÿè¡Œ
        demos = [
            ("ã‚»ã‚¯ã‚·ãƒ§ãƒ‹ãƒ³ã‚°", "sectioning", processor.process_sectioning),
            ("æŠ•ç¥¨", "voting", processor.process_voting),
            ("ã‚³ãƒ¼ãƒ‰ãƒ¬ãƒ“ãƒ¥ãƒ¼", "review", processor.process_review),
        ]

        for demo_name, data_key, process_func in demos:
            print(f"\nã€{demo_name}ãƒ‡ãƒ¢ã€‘")
            print("=" * 40)

            # å‡¦ç†ã‚’å®Ÿè¡Œ
            result = process_func(demo_data[data_key])

            # çµæœã®è¡¨ç¤º
            print("\nğŸ“Š å‡¦ç†çµæœ:")
            print(f"å‡¦ç†ã‚¿ã‚¤ãƒ—: {result['processing_type']}")
            print(f"ä¸¦åˆ—å‡¦ç†æ•°: {len(result['parallel_results'])}")
            print(f"å®Ÿè¡Œæ™‚é–“: {result['execution_time']:.2f}ç§’")

            print("\nğŸ“ æœ€çµ‚ã‚µãƒãƒªãƒ¼:")
            print(
                result["final_summary"][:300] + "..."
                if len(result["final_summary"]) > 300
                else result["final_summary"]
            )

            # è©³ç´°è¡¨ç¤ºã®ç¢ºèª
            show_details = input("\nè©³ç´°ã‚’è¡¨ç¤ºã—ã¾ã™ã‹ï¼Ÿ (y/n): ").lower().strip()
            if show_details == "y":
                print("\n" + "=" * 50)
                print("ğŸ“‹ è©³ç´°çµæœ")
                print("=" * 50)

                print("\nâš¡ ä¸¦åˆ—å‡¦ç†çµæœ:")
                for key, value in result["parallel_results"].items():
                    print(f"\n--- {key} ---")
                    print(value)

                print("\nğŸ“Š å®Ÿè¡Œãƒ­ã‚°:")
                for log_entry in result["execution_log"]:
                    print(f"  {log_entry}")

            print()

        # ã‚«ã‚¹ã‚¿ãƒ å‡¦ç†ãƒ¢ãƒ¼ãƒ‰
        print("\n" + "=" * 60)
        print("ğŸ’¬ ã‚«ã‚¹ã‚¿ãƒ ä¸¦åˆ—å‡¦ç†ãƒ¢ãƒ¼ãƒ‰ (çµ‚äº†ã™ã‚‹ã«ã¯ 'quit' ã¨å…¥åŠ›)")
        print("=" * 60)

        while True:
            try:
                print("\nå‡¦ç†ã‚¿ã‚¤ãƒ—ã‚’é¸æŠã—ã¦ãã ã•ã„:")
                print("1. ã‚»ã‚¯ã‚·ãƒ§ãƒ‹ãƒ³ã‚°ï¼ˆæ–‡æ›¸åˆ†å‰²ï¼‰")
                print("2. æŠ•ç¥¨ï¼ˆè¤‡æ•°è©•ä¾¡è€…ã«ã‚ˆã‚‹è©•ä¾¡ï¼‰")
                print("3. ã‚³ãƒ¼ãƒ‰ãƒ¬ãƒ“ãƒ¥ãƒ¼ï¼ˆè¤‡æ•°ãƒ¬ãƒ“ãƒ¥ã‚¢ãƒ¼ï¼‰")

                choice = input("\né¸æŠ (1-3): ").strip()

                if choice.lower() in ["quit", "exit", "çµ‚äº†", "q"]:
                    print("ğŸ‘‹ å‡¦ç†ã‚’çµ‚äº†ã—ã¾ã™ã€‚")
                    break

                if choice not in ["1", "2", "3"]:
                    print("âš ï¸  1-3ã®æ•°å­—ã‚’é¸æŠã—ã¦ãã ã•ã„ã€‚")
                    continue

                input_text = input("\nå‡¦ç†ã—ãŸã„ãƒ†ã‚­ã‚¹ãƒˆã‚’å…¥åŠ›ã—ã¦ãã ã•ã„:\n").strip()

                if not input_text:
                    print("âš ï¸  ãƒ†ã‚­ã‚¹ãƒˆã‚’å…¥åŠ›ã—ã¦ãã ã•ã„ã€‚")
                    continue

                # é¸æŠã«å¿œã˜ã¦å‡¦ç†ã‚’å®Ÿè¡Œ
                if choice == "1":
                    result = processor.process_sectioning(input_text)
                elif choice == "2":
                    result = processor.process_voting(input_text)
                else:  # choice == '3'
                    result = processor.process_review(input_text)

                # çµæœã®è¡¨ç¤º
                print(f"\nğŸ‰ å‡¦ç†å®Œäº†ï¼ (å®Ÿè¡Œæ™‚é–“: {result['execution_time']:.2f}ç§’)")
                print("ğŸ“ çµæœã‚µãƒãƒªãƒ¼:")
                print("-" * 40)
                print(result["final_summary"])

            except KeyboardInterrupt:
                print("\n\nğŸ‘‹ å‡¦ç†ã‚’çµ‚äº†ã—ã¾ã™ã€‚")
                break

    except Exception as e:
        print(f"âŒ ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}")
        print("ğŸ’¡ OpenAI APIã‚­ãƒ¼ãŒæ­£ã—ãè¨­å®šã•ã‚Œã¦ã„ã‚‹ã‹ç¢ºèªã—ã¦ãã ã•ã„ã€‚")


if __name__ == "__main__":
    main()
