{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install langchain-core==0.3.0 langchain-openai==0.2.0 pydantic==2.10.6"
      ],
      "metadata": {
        "id": "hGUko88NyPw9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "Axoi8Al5lSb0"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "from google.colab import userdata\n",
        "\n",
        "os.environ[\"OPENAI_API_KEY\"] = userdata.get(\"OPENAI_API_KEY\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "LLM"
      ],
      "metadata": {
        "id": "Fcew50HG1LsF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_openai import OpenAI\n",
        "\n",
        "model = OpenAI(model=\"gpt-3.5-turbo-instruct\", temperature=0)\n",
        "ai_message = model.invoke(\"こんにちは\")\n",
        "print(ai_message)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qOaOGx1szAtY",
        "outputId": "2b515fdf-c553-40d2-f9aa-540deff96409"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "こんにちは\n",
            "\n",
            "こんにちは、私はAIのアシスタントです。あなたのお手伝いをすることができます。何かお困りのことはありますか？\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Chat model"
      ],
      "metadata": {
        "id": "ry1Rh-KK1Hc7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_core.messages import AIMessage, HumanMessage, SystemMessage\n",
        "from langchain_openai import ChatOpenAI\n",
        "\n",
        "model = ChatOpenAI(model=\"gpt-4o-mini\", temperature=0)\n",
        "\n",
        "messages = [\n",
        "    SystemMessage(\"You are a helpful assistant.\"),\n",
        "    HumanMessage(\"こんにちは！私はジョンと言います\"),\n",
        "    AIMessage(content=\"こんにちは、ジョンさん！どのようにお手伝いできますか？\"),\n",
        "    HumanMessage(content=\"私の名前がわかりますか？\"),\n",
        "]\n",
        "print(messages)\n",
        "ai_message = model.invoke(messages)\n",
        "print(ai_message)\n",
        "print(ai_message.content)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "81yLyVxw0WsD",
        "outputId": "2114ba08-f7dc-4329-e3ef-81540c145219"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[SystemMessage(content='You are a helpful assistant.', additional_kwargs={}, response_metadata={}), HumanMessage(content='こんにちは！私はジョンと言います', additional_kwargs={}, response_metadata={}), AIMessage(content='こんにちは、ジョンさん！どのようにお手伝いできますか？', additional_kwargs={}, response_metadata={}), HumanMessage(content='私の名前がわかりますか？', additional_kwargs={}, response_metadata={})]\n",
            "content='はい、あなたの名前はジョンさんです。何か特別なことについてお話ししたいですか？' additional_kwargs={'refusal': None} response_metadata={'token_usage': {'completion_tokens': 26, 'prompt_tokens': 58, 'total_tokens': 84, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_34a54ae93c', 'finish_reason': 'stop', 'logprobs': None} id='run-54e75cf9-beff-4975-89d6-06a4be0cc1a0-0' usage_metadata={'input_tokens': 58, 'output_tokens': 26, 'total_tokens': 84}\n",
            "はい、あなたの名前はジョンさんです。何か特別なことについてお話ししたいですか？\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "ストリーミング"
      ],
      "metadata": {
        "id": "z3Qh6D_M1CnJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_core.messages import SystemMessage, HumanMessage\n",
        "from langchain_openai import ChatOpenAI\n",
        "\n",
        "model = ChatOpenAI(model=\"gpt-4o-mini\", temperature=0)\n",
        "\n",
        "messages = [\n",
        "    SystemMessage(\"You are a helpful assistant.\"),\n",
        "    HumanMessage(\"こんにちは！\"),\n",
        "]\n",
        "\n",
        "for chunk in model.stream(messages):\n",
        "    print(chunk.content, end=\"\", flush=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vA9Q1OVi1FMN",
        "outputId": "5f03042b-75c5-459f-e42a-b05f94e7aff2"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "こんにちは！どのようにお手伝いできますか？"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "PromptTemplate"
      ],
      "metadata": {
        "id": "nRFfcjlp17ER"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_core.prompts import PromptTemplate\n",
        "\n",
        "prompt = PromptTemplate.from_template(\"\"\"\n",
        "以下の料理のレシピを考えてください。\n",
        "\n",
        "料理名: {dish}\n",
        "\"\"\")\n",
        "\n",
        "prompt_value = prompt.invoke({\"dish\": \"カレー\"})\n",
        "print(prompt_value.text)\n",
        "\n",
        "# ＜補足：プロンプトの変数が 1 つの場合＞\n",
        "prompt_value = prompt.invoke(\"カレー\")\n",
        "print(prompt_value.text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PXiarZZB19Le",
        "outputId": "2afb6cdc-f129-417d-e22b-8ec9fb8f78d4"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "以下の料理のレシピを考えてください。\n",
            "\n",
            "料理名: カレー\n",
            "\n",
            "\n",
            "以下の料理のレシピを考えてください。\n",
            "\n",
            "料理名: カレー\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "ChatPromptTemplate"
      ],
      "metadata": {
        "id": "neBm25yG2iCd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_core.prompts import ChatPromptTemplate\n",
        "\n",
        "prompt = ChatPromptTemplate.from_messages(\n",
        "    [\n",
        "        (\"system\", \"ユーザーが入力した料理のレシピを考えてください。\"),\n",
        "        (\"human\", \"{dish}\"),\n",
        "        HumanMessage(\"{dish}\"),  # [メモ] HumanMessage(\"{dish}\") では置き換えられない\n",
        "    ]\n",
        ")\n",
        "\n",
        "prompt_value = prompt.invoke({\"dish\": \"カレー\"})\n",
        "print(prompt_value)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R1nBuJUz2kG6",
        "outputId": "aff88de4-2447-45ae-bddf-3f0a97f32dee"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "messages=[SystemMessage(content='ユーザーが入力した料理のレシピを考えてください。', additional_kwargs={}, response_metadata={}), HumanMessage(content='カレー', additional_kwargs={}, response_metadata={}), HumanMessage(content='{dish}', additional_kwargs={}, response_metadata={})]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "MessagesPlaceholder"
      ],
      "metadata": {
        "id": "zJ_ZkDSJ3UCo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_core.messages import AIMessage, HumanMessage\n",
        "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
        "\n",
        "prompt = ChatPromptTemplate.from_messages(\n",
        "    [\n",
        "        (\"system\", \"You are a helpful assistant.\"),\n",
        "        MessagesPlaceholder(\"chat_history\", optional=True),\n",
        "        (\"human\", \"{input}\"),\n",
        "    ]\n",
        ")\n",
        "\n",
        "prompt_value = prompt.invoke(\n",
        "    {\n",
        "        \"chat_history\": [\n",
        "            HumanMessage(content=\"こんにちは！私はジョンと言います！\"),\n",
        "            AIMessage(\"こんにちは、ジョンさん！どのようにお手伝いできますか？\"),\n",
        "        ],\n",
        "        \"input\": \"私の名前が分かりますか？\",\n",
        "    }\n",
        ")\n",
        "print(prompt_value)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "03wDdSAW3V1_",
        "outputId": "c3ce6362-bf12-4407-82bc-20c7b1e2e52e"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "messages=[SystemMessage(content='You are a helpful assistant.', additional_kwargs={}, response_metadata={}), HumanMessage(content='こんにちは！私はジョンと言います！', additional_kwargs={}, response_metadata={}), AIMessage(content='こんにちは、ジョンさん！どのようにお手伝いできますか？', additional_kwargs={}, response_metadata={}), HumanMessage(content='私の名前が分かりますか？', additional_kwargs={}, response_metadata={})]\n",
            "content='はい、あなたの名前はジョンさんですね！他に何かお話ししたいことがありますか？' additional_kwargs={'refusal': None} response_metadata={'token_usage': {'completion_tokens': 24, 'prompt_tokens': 59, 'total_tokens': 83, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_34a54ae93c', 'finish_reason': 'stop', 'logprobs': None} id='run-b5df55e9-d6a6-4181-8787-826de300c871-0' usage_metadata={'input_tokens': 59, 'output_tokens': 24, 'total_tokens': 83}\n",
            "はい、あなたの名前はジョンさんですね！他に何かお話ししたいことがありますか？\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "PydanticOutputParser を使った Python オブジェクトへの変換"
      ],
      "metadata": {
        "id": "iNSC1Mlw5gKQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pydantic import BaseModel, Field\n",
        "from langchain_core.output_parsers import PydanticOutputParser\n",
        "\n",
        "class Recipe(BaseModel):\n",
        "    ingredients: list[str] = Field(description=\"ingredients of the dish\")\n",
        "    steps: list[str] = Field(description=\"steps to make the dish\")\n",
        "\n",
        "output_parser = PydanticOutputParser(pydantic_object=Recipe)\n",
        "\n",
        "format_instructions = output_parser.get_format_instructions()\n",
        "print(format_instructions)\n",
        "\n",
        "prompt = ChatPromptTemplate.from_messages(\n",
        "    [\n",
        "        (\n",
        "            \"system\",\n",
        "            \"ユーザーが入力した料理のレシピを考えてください。\\n\\n\"\n",
        "            \"{format_instructions}\",  # [メモ] 単にJSONフォーマットを指定する文字が埋め込まれるに過ぎない\n",
        "        ),\n",
        "        (\"human\", \"{dish}\"),\n",
        "    ]\n",
        ")\n",
        "\n",
        "prompt_with_format_instructions = prompt.partial(\n",
        "    format_instructions=format_instructions\n",
        ")\n",
        "\n",
        "prompt_value = prompt_with_format_instructions.invoke({\"dish\": \"カレー\"})\n",
        "print(\"=== role: system ===\")\n",
        "print(prompt_value.messages[0].content)\n",
        "print(\"=== role: user ===\")\n",
        "print(prompt_value.messages[1].content)\n",
        "\n",
        "print(\"=== LLM結果 ===\")\n",
        "ai_message = model.invoke(prompt_value)\n",
        "print(ai_message.content)\n",
        "\n",
        "print(\"=== Pythonオブジェクト化 ===\")\n",
        "recipe = output_parser.invoke(ai_message)\n",
        "print(type(recipe))\n",
        "print(recipe)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2DsOszmh5hD5",
        "outputId": "a2c98190-f6ba-4357-a122-4ca919a6d724"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The output should be formatted as a JSON instance that conforms to the JSON schema below.\n",
            "\n",
            "As an example, for the schema {\"properties\": {\"foo\": {\"title\": \"Foo\", \"description\": \"a list of strings\", \"type\": \"array\", \"items\": {\"type\": \"string\"}}}, \"required\": [\"foo\"]}\n",
            "the object {\"foo\": [\"bar\", \"baz\"]} is a well-formatted instance of the schema. The object {\"properties\": {\"foo\": [\"bar\", \"baz\"]}} is not well-formatted.\n",
            "\n",
            "Here is the output schema:\n",
            "```\n",
            "{\"properties\": {\"ingredients\": {\"description\": \"ingredients of the dish\", \"items\": {\"type\": \"string\"}, \"title\": \"Ingredients\", \"type\": \"array\"}, \"steps\": {\"description\": \"steps to make the dish\", \"items\": {\"type\": \"string\"}, \"title\": \"Steps\", \"type\": \"array\"}}, \"required\": [\"ingredients\", \"steps\"]}\n",
            "```\n",
            "=== role: system ===\n",
            "ユーザーが入力した料理のレシピを考えてください。\n",
            "\n",
            "The output should be formatted as a JSON instance that conforms to the JSON schema below.\n",
            "\n",
            "As an example, for the schema {\"properties\": {\"foo\": {\"title\": \"Foo\", \"description\": \"a list of strings\", \"type\": \"array\", \"items\": {\"type\": \"string\"}}}, \"required\": [\"foo\"]}\n",
            "the object {\"foo\": [\"bar\", \"baz\"]} is a well-formatted instance of the schema. The object {\"properties\": {\"foo\": [\"bar\", \"baz\"]}} is not well-formatted.\n",
            "\n",
            "Here is the output schema:\n",
            "```\n",
            "{\"properties\": {\"ingredients\": {\"description\": \"ingredients of the dish\", \"items\": {\"type\": \"string\"}, \"title\": \"Ingredients\", \"type\": \"array\"}, \"steps\": {\"description\": \"steps to make the dish\", \"items\": {\"type\": \"string\"}, \"title\": \"Steps\", \"type\": \"array\"}}, \"required\": [\"ingredients\", \"steps\"]}\n",
            "```\n",
            "=== role: user ===\n",
            "カレー\n",
            "=== LLM結果 ===\n",
            "{\n",
            "  \"ingredients\": [\n",
            "    \"鶏肉 500g\",\n",
            "    \"玉ねぎ 2個\",\n",
            "    \"にんじん 1本\",\n",
            "    \"じゃがいも 2個\",\n",
            "    \"カレールー 1箱\",\n",
            "    \"水 800ml\",\n",
            "    \"サラダ油 大さじ2\",\n",
            "    \"塩 適量\",\n",
            "    \"こしょう 適量\"\n",
            "  ],\n",
            "  \"steps\": [\n",
            "    \"鶏肉は一口大に切り、塩とこしょうをふる。\",\n",
            "    \"玉ねぎは薄切り、にんじんは輪切り、じゃがいもは一口大に切る。\",\n",
            "    \"鍋にサラダ油を熱し、玉ねぎを炒めて透明になるまで炒める。\",\n",
            "    \"鶏肉を加え、表面が白くなるまで炒める。\",\n",
            "    \"にんじんとじゃがいもを加え、さらに炒める。\",\n",
            "    \"水を加え、煮立ったらアクを取り除く。\",\n",
            "    \"弱火にして、約20分煮込む。\",\n",
            "    \"カレールーを加え、溶かしながらさらに10分煮込む。\",\n",
            "    \"味を見て、必要に応じて塩で調整する。\",\n",
            "    \"ご飯と一緒に盛り付けて完成。\"\n",
            "  ]\n",
            "}\n",
            "=== Pythonオブジェクト化 ===\n",
            "<class '__main__.Recipe'>\n",
            "ingredients=['鶏肉 500g', '玉ねぎ 2個', 'にんじん 1本', 'じゃがいも 2個', 'カレールー 1箱', '水 800ml', 'サラダ油 大さじ2', '塩 適量', 'こしょう 適量'] steps=['鶏肉は一口大に切り、塩とこしょうをふる。', '玉ねぎは薄切り、にんじんは輪切り、じゃがいもは一口大に切る。', '鍋にサラダ油を熱し、玉ねぎを炒めて透明になるまで炒める。', '鶏肉を加え、表面が白くなるまで炒める。', 'にんじんとじゃがいもを加え、さらに炒める。', '水を加え、煮立ったらアクを取り除く。', '弱火にして、約20分煮込む。', 'カレールーを加え、溶かしながらさらに10分煮込む。', '味を見て、必要に応じて塩で調整する。', 'ご飯と一緒に盛り付けて完成。']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "StrOutputParser"
      ],
      "metadata": {
        "id": "0lJG49sN8CE4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_core.messages import AIMessage\n",
        "from langchain_core.output_parsers import StrOutputParser\n",
        "\n",
        "output_parser = StrOutputParser()\n",
        "\n",
        "ai_message = AIMessage(content=\"こんにちは。私はAIアシスタントです。\")\n",
        "print(ai_message)\n",
        "ai_message = output_parser.invoke(ai_message) # [メモ] content の中を取りだしている\n",
        "print(type(ai_message))\n",
        "print(ai_message)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2QYYXOvb8D0t",
        "outputId": "b414825c-dfe3-422f-f076-e53374178c47"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "content='こんにちは。私はAIアシスタントです。' additional_kwargs={} response_metadata={}\n",
            "<class 'str'>\n",
            "こんにちは。私はAIアシスタントです。\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "LangChain Expression Language（LCEL）"
      ],
      "metadata": {
        "id": "xoQ8wGrM8eqc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_core.prompts import ChatPromptTemplate\n",
        "from langchain_openai import ChatOpenAI\n",
        "\n",
        "prompt = ChatPromptTemplate.from_messages(\n",
        "    [\n",
        "        (\"system\", \"ユーザーが入力した料理のレシピを考えてください。\"),\n",
        "        (\"human\", \"{dish}\"),\n",
        "    ]\n",
        ")\n",
        "\n",
        "model = ChatOpenAI(model_name=\"gpt-4o-mini\", temperature=0)\n",
        "\n",
        "# [メモ] Templateプロンプトを invoke して、model を invoke して…を1回で\n",
        "chain = prompt | model | StrOutputParser()\n",
        "ai_message = chain.invoke({\"dish\": \"カレー\"})\n",
        "print(ai_message)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yfdQcTfS8g6H",
        "outputId": "4547f15f-34a9-46db-89b8-e0dc05b54328"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "カレーのレシピをご紹介します！以下は基本的なチキンカレーのレシピです。\n",
            "\n",
            "### 材料（4人分）\n",
            "- 鶏もも肉：400g（大きめの一口大にカット）\n",
            "- 玉ねぎ：2個（みじん切り）\n",
            "- にんにく：2片（みじん切り）\n",
            "- 生姜：1片（みじん切り）\n",
            "- トマト：1個（ざく切り）\n",
            "- カレーパウダー：大さじ2\n",
            "- クミンシード：小さじ1\n",
            "- ココナッツミルク：200ml（お好みで）\n",
            "- サラダ油：大さじ2\n",
            "- 塩：適量\n",
            "- 胡椒：適量\n",
            "- 水：400ml\n",
            "- パクチー（飾り用）：適量\n",
            "\n",
            "### 作り方\n",
            "1. **下ごしらえ**: 鶏肉に塩と胡椒をふり、下味をつけておきます。\n",
            "2. **玉ねぎを炒める**: 大きめの鍋にサラダ油を熱し、みじん切りにした玉ねぎを加え、中火で透明になるまで炒めます。\n",
            "3. **香辛料を加える**: にんにく、生姜、クミンシードを加え、香りが立つまでさらに炒めます。\n",
            "4. **鶏肉を加える**: 鶏肉を鍋に加え、表面が白くなるまで炒めます。\n",
            "5. **トマトとカレー粉を加える**: ざく切りにしたトマトとカレーパウダーを加え、全体をよく混ぜます。\n",
            "6. **煮込む**: 水を加え、沸騰したら弱火にして蓋をし、約20分煮込みます。途中でアクが出たら取り除きます。\n",
            "7. **ココナッツミルクを加える**: 最後にココナッツミルクを加え、さらに5分ほど煮込みます。味を見て、必要に応じて塩で調整します。\n",
            "8. **盛り付け**: お皿に盛り付け、パクチーを散らして完成です。\n",
            "\n",
            "### 提供方法\n",
            "ご飯やナンと一緒にお召し上がりください。お好みでヨーグルトやサラダを添えると、より美味しく楽しめます。\n",
            "\n",
            "ぜひお試しください！\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "PydanticOutputParser を使う連鎖"
      ],
      "metadata": {
        "id": "QdrMjJ1o9W4U"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_core.output_parsers import PydanticOutputParser\n",
        "from pydantic import BaseModel, Field\n",
        "from langchain_core.prompts import ChatPromptTemplate\n",
        "from langchain_openai import ChatOpenAI\n",
        "\n",
        "\n",
        "class Recipe(BaseModel):\n",
        "    ingredients: list[str] = Field(description=\"ingredients of the dish\")\n",
        "    steps: list[str] = Field(description=\"steps to make the dish\")\n",
        "\n",
        "\n",
        "output_parser = PydanticOutputParser(pydantic_object=Recipe)\n",
        "\n",
        "prompt = ChatPromptTemplate.from_messages(\n",
        "    [\n",
        "        (\"system\", \"ユーザーが入力した料理のレシピを考えてください。\\n\\n{format_instructions}\"),\n",
        "        (\"human\", \"{dish}\"),\n",
        "    ]\n",
        ")\n",
        "\n",
        "prompt_with_format_instructions = prompt.partial(\n",
        "    format_instructions=output_parser.get_format_instructions()\n",
        ")\n",
        "\n",
        "model = ChatOpenAI(model=\"gpt-4o-mini\", temperature=0).bind(\n",
        "    response_format={\"type\": \"json_object\"}\n",
        ")\n",
        "\n",
        "chain = prompt_with_format_instructions | model | output_parser\n",
        "\n",
        "recipe = chain.invoke({\"dish\": \"カレー\"})\n",
        "print(type(recipe))\n",
        "print(recipe)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OljQQE7i9Y0W",
        "outputId": "74d1b0d1-d94f-4ee0-ed85-54a79903a2bb"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class '__main__.Recipe'>\n",
            "ingredients=['鶏肉 500g', '玉ねぎ 2個', 'にんじん 1本', 'じゃがいも 2個', 'カレールー 1箱', '水 800ml', 'サラダ油 大さじ2', '塩 適量', 'こしょう 適量'] steps=['鶏肉は一口大に切り、塩とこしょうをふる。', '玉ねぎは薄切り、にんじんとじゃがいもは一口大に切る。', '鍋にサラダ油を熱し、玉ねぎを炒めて透明になるまで炒める。', '鶏肉を加え、表面が白くなるまで炒める。', 'にんじんとじゃがいもを加え、全体を混ぜる。', '水を加え、沸騰したらアクを取り、弱火で20分煮る。', 'カレールーを加え、よく溶かしてさらに10分煮る。', '味を見て、必要に応じて塩で調整する。', 'ご飯と一緒に盛り付けて完成。']\n"
          ]
        }
      ]
    }
  ]
}